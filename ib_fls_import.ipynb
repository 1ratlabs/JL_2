{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98299ccf-3813-4908-b2cb-110b5d26dd77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# *Procedure* for building \" *The df_ib DataFrame from ib770 & ib970 combined with meta_data*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb72ef-b02f-48c2-a659-88d6c3fee5e2",
   "metadata": {},
   "source": [
    "# Import Subroutines and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc44cd5a-40d5-4bff-8dde-de21b6877ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bhuns/miniconda3/bin/python\n",
      "note: THIS IS THE DIRECTORY PYTHON IS WORKING IN.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(\"note: THIS IS THE DIRECTORY PYTHON IS WORKING IN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1c6941-4bbc-421d-bcf4-ee3bb2055a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required for Loading, sorting .csx files to create specific data sets ie mrn inbody readings. \n",
    "%run ./sys_funcs.py              # loads all the def functions in sys_funcs.py into memory\n",
    "#import sys_funcs                 # gives access to these def function digitalform that are in memory\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import time\n",
    "from sys_funcs import read_csv_to_array\n",
    "from sys_funcs import clean_wsl_path\n",
    "from sys_funcs import array_to_dt_row_dict\n",
    "from sys_funcs import make_blnk_update_row_dict\n",
    "from sys_funcs import transpose_csv_to_col_dict\n",
    "#from sys_funcs import update_values_with_config, get_update_result\n",
    "from sys_funcs import transfer_updates\n",
    "from sys_funcs import get_dtv_range\n",
    "from sys_funcs import universal_import\n",
    "from sys_funcs import parse_inbody_timestamp\n",
    "from sys_funcs import build_lut\n",
    "from sys_funcs import extract_a_column_as_df\n",
    "from sys_funcs import extract_multicolumns_as_df\n",
    "from sys_funcs import validate_and_sort_timestamps\n",
    "from sys_funcs import extract_and_filter_by_time_window\n",
    "from sys_funcs import read_file_dual_path\n",
    "from sys_funcs import write_file_dual_path\n",
    "from sys_funcs import asc_to_csv_cnv\n",
    "from collections.abc import Mapping\n",
    "import re\n",
    "#from sys_funcs import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40073c29-4be1-4d3f-86a4-f44d70c3d61f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print set to 1000 rows max\n"
     ]
    }
   ],
   "source": [
    "# set print rows  This worksheet sets maximum # of rows printed\n",
    "pd.set_option('display.max_rows', 1000)  # Adjust the number of rows to display\n",
    "# pd.reset_option('display.max_rows')  \n",
    "print('print set to 1000 rows max' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac9c77-ea9b-4519-a678-5b00f0dd9e9d",
   "metadata": {},
   "source": [
    "# Startup only Create  **df_ib_fls_tmplt**  ie  *[COL_NMS = meta+ib770dat + ib970dat]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee2ceb-7049-4a74-ae6b-063b75127891",
   "metadata": {},
   "source": [
    "## Add the columns of df_77 & df_97 then delete Column names and add meta cols and Store as data frames in pickle called *df_ib_tst_nms*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a42f9e-d00c-4f74-a536-984b753b7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this def function STRIPS COL NMBRS  column #s from col heads used only in making the files\n",
    "\n",
    "def strip_col_numbers(col_names):\n",
    "    \"\"\"\n",
    "    Remove leading numbers and dots from column names.\n",
    "    Example: '244. 50kHz-Whole Body Phase Angle_Z score' \n",
    "             -> '50kHz-Whole Body Phase Angle_Z score'\n",
    "    \"\"\"\n",
    "    return [re.sub(r'^\\d+\\.\\s*', '', name) for name in col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b19fd-38a3-48f5-a69e-70d9d626b36d",
   "metadata": {},
   "source": [
    "### ib77  This segment Reads the data from the excel file and computes names of the column head, strips them of numbers and Puts them in a data frame and records them in a pickle. *\"df_ib77_raw_nms\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281a9a52-46a3-4778-9dee-faa22d2002aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 091725_20251213054921.csv with utf-8\n",
      "âœ… Loaded 091725_20251214234814.csv with utf-8\n",
      "âœ… Loaded 091725_20251217075000.csv with utf-8\n",
      "âœ… Loaded 091725_20251218081604.csv with utf-8\n",
      "âœ… Loaded 091725_20251216233809.csv with utf-8\n",
      "âœ… Loaded 091725_20251215080038.csv with utf-8\n",
      "âœ… Loaded 091725-1_20251212221713.csv with utf-8\n",
      "âœ… Loaded 091725_20251219080729.csv with utf-8\n",
      "âœ… Loaded 091725_20251214090336.csv with utf-8\n",
      "âœ… Loaded 091725_20251218212747.csv with utf-8\n",
      "âœ… Loaded 091725_20251219232758.csv with utf-8\n",
      "âœ… Loaded 091725_20251215233324.csv with utf-8\n",
      "âœ… Loaded 091725_20251216064808.csv with utf-8\n",
      "âœ… Loaded 091725-1_20251211092610.csv with utf-8\n",
      "âœ… Loaded 091725_20251217230745.csv with utf-8\n",
      "âœ… Loaded 091725_20251220085024.csv with utf-8\n",
      "âœ… Loaded 091725-1_20251212084231.csv with utf-8\n",
      "âœ… [imported_dataframe] Final DataFrame: 17 rows from 17 files.\n",
      "ðŸ’¾ Saved to pickle: /home/bhuns/JL_2/imported_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "# loads the new from the 770\n",
    "ib77_raw = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib77\",\n",
    "    pattern=\"*\"\n",
    ")\n",
    "# strip numbers off So that the identical names in IB77 are the same as IB97\n",
    "ib77_raw_nms = strip_col_numbers(ib77_raw)\n",
    "# Now we'll make it into a data frame so that we will print it in a column which obey list [numbers separated by commas]\n",
    "df_ib77_raw_nms = pd.DataFrame(ib77_raw_nms)\n",
    "\n",
    "# Load to pickle file in the working directory\n",
    "df_ib77_raw_nms.to_pickle(\"df_ib77_raw_nms.pkl\")\n",
    "\n",
    "# For verification the picket file and print its value.\n",
    "df_ib77_raw_nms = pd.read_pickle(\"df_ib77_raw_nms.pkl\")\n",
    "\n",
    "# verify \n",
    "# print(ib77_raw_nms)\n",
    "# verify print(\"df_ib77_raw_nms \\n\",df_ib77_raw_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a572b8-bd9b-4e50-8053-583ca140a60d",
   "metadata": {},
   "source": [
    "### ib97 This segment Reads the data from the excel file and computes names of the column head, strips them of numbers and Puts them in a data frame and records them in a pickle. *\"df_ib97_raw_nms\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317087a4-d603-4910-a58e-adfc1397d638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 091725_bdailyn_20250922225826.csv with ISO-8859-1\n",
      "âœ… [imported_dataframe] Final DataFrame: 1 rows from 1 files.\n",
      "ðŸ’¾ Saved to pickle: /home/bhuns/JL_2/imported_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "ib97_raw = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib97\",\n",
    "    pattern=\"*\"\n",
    ")\n",
    "# strip numbers off So that the identical names in IB97 are the same as IB97\n",
    "ib97_raw_nms = strip_col_numbers(ib97_raw)\n",
    "# Now we'll make it into a data frame so that we will print it in a column which obey list [numbers separated by commas]\n",
    "df_ib97_raw_nms = pd.DataFrame(ib97_raw_nms)\n",
    "\n",
    "# Load to pickle file in the working directory\n",
    "df_ib97_raw_nms.to_pickle(\"df_ib97_raw_nms.pkl\")\n",
    "\n",
    "# For verification the picket file and print its value.\n",
    "df_ib97_raw_nms = pd.read_pickle(\"df_ib97_raw_nms.pkl\")\n",
    "\n",
    "# verify \n",
    "# print(ib97_raw_nms)\n",
    "# verify \n",
    "# print(\"df_ib97_raw_nms \\n\",df_ib97_raw_nms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2314cef7-0753-46cb-9da3-28a3a1968b43",
   "metadata": {},
   "source": [
    "### Both the 77 and the 90 test datasets are convrted to dfs In order to determine *df_ib_tst_nms* Which is a single column data frame that all of the column names of the *df_ib_tst*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb2f2af-640c-418d-b976-f966ed95e981",
   "metadata": {},
   "source": [
    "#### âœ… Concatenate â†’ Preserve Order â†’ Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162178e7-84e1-4591-9be5-c2fb1c903aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Concatenate â†’ Preserve Order â†’ Drop Duplicates mmmmmmmmmnnnnnnnllllll\n",
    "# Concatenate in the required order\n",
    "df_ib_tst_nms = pd.concat(\n",
    "    [df_ib77_raw_nms, df_ib97_raw_nms],\n",
    "    axis=0,\n",
    "    ignore_index=True\n",
    ")\n",
    "# print(df_ib_tst_nms)\n",
    "# Remove duplicate rows, keeping the first occurrence (from df_ib77_raw_nms)\n",
    "df_ib_tst_nms = df_ib_tst_nms.drop_duplicates(keep=\"first\")\n",
    "# verify \n",
    "# print(df_ib_tst_nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fda01c2-e3f4-43f6-a730-78af5ba12e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifies that the duplicates have been removed and that the list has been compacted and there are not duplicates of 770 and 970 Col\n",
    "df_ib_tst_nms[df_ib_tst_nms.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c4d50e-0a5b-4074-9da9-b3d85ca13fbf",
   "metadata": {},
   "source": [
    "### *df_ib_tst_nms* must be converted to a simple list in order to made equal to the column heads of df_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c74182-c2e5-41ae-937b-54882528df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The large test data frame that will be used to accept values of each from both 770 N 970 will be built on the basis of the df_ib_tst_nms, but this data bugs be in form of a strings.\n",
    "# df['colname'].astype(str).tolist       # sign This is the sample given from copilot that is modified below for my situation \n",
    "\n",
    "ib_tst_lst = df_ib_tst_nms[0].astype(str).tolist()\n",
    "# verify \n",
    "# print(ib_tst_lst)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68b5135d-8592-4d58-9002-cbd154f61251",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#  Raw not needed\n",
    "df_ib_tst.columns = [\n",
    "    \"_\".join([str(c) for c in col]).strip()\n",
    "    if isinstance(col, tuple) else col\n",
    "    for col in df_ib_tst.columns\n",
    "]\n",
    "df_ib_tst[\"ID\"]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5e4eebc-ece3-4137-ab01-97f6005a6654",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# RAW Since the column names are listed in a data frame That makes each one a tuple. It must be a string. Line makes it a string and the column a list of strings.\n",
    "df_ib_tst_nms = [col[0] if isinstance(col, tuple) else col for col in df_ib_tst_nms]\n",
    "df_ib_tst_nms = df_ib_tst.columns \n",
    "df_ib_tst_nms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21ba0884-3bf5-46ed-87bd-d38a3edd4595",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "raw\n",
    "df_ib_tst.columns = [col[0] if isinstance(col, tuple) else col for col in df_ib_tst.columns]\n",
    "df_ib_tst.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73e6f09a-ac5f-48a9-a379-e732c8c5194b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ib_tst_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# this makes the template for the ib_tst data For both the 770 and the 970 It is made up of a 770 and a 970 with duplicates eliminated in a list of strings\u001b[39;00m\n\u001b[32m      3\u001b[39m df_ib_tst = pd.DataFrame(\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     data = [[\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(\u001b[43mdf_ib_tst_lst\u001b[49m)] * \u001b[32m2\u001b[39m,\n\u001b[32m      5\u001b[39m     columns = ib_tst_lst\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#df_ib_tst_nms\u001b[39;00m\n\u001b[32m      8\u001b[39m df_ib_tst\n",
      "\u001b[31mNameError\u001b[39m: name 'df_ib_tst_lst' is not defined"
     ]
    }
   ],
   "source": [
    "# this makes the template for the ib_tst data For both the 770 and the 970 It is made up of a 770 and a 970 with duplicates eliminated in a list of strings\n",
    "\n",
    "df_ib_tst = pd.DataFrame(\n",
    "    data = [[\"\"] * len(df_ib_tst_lst)] * 2,\n",
    "    columns = ib_tst_lst\n",
    ")\n",
    "#df_ib_tst_nms\n",
    "df_ib_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581a42d-3b59-4274-b436-8b70c3b2dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests \n",
    "df_ib_tst[\"ID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786015c-3b7b-4611-9130-38413ff07172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib_tst.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7350e-6a9e-44f5-8ec3-2602489ec699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib_tst[\"ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3a3a0-5574-47d4-82ef-3094931cd707",
   "metadata": {},
   "source": [
    "# The following is the procedure to edit_ This structure of â€ ib_tstâ€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3cf4af-3568-4d4a-b892-9b4406dd0db6",
   "metadata": {},
   "source": [
    "## data frame of the main data storage_â€œib_tst\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf894513-6122-4256-9011-3c35d9133682",
   "metadata": {},
   "source": [
    "###  Make the edits to the structure of the main data spreadsheet that represents structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855723c-7ca0-45f8-b26a-d8d49c37997d",
   "metadata": {},
   "source": [
    "### Then the CSV file into the worksheet to display the changes in Jupiter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca560b7-1dad-43b3-b1cd-41c85e021ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_csv(\"/home/bhuns/JL_2/data/ib_tst/ib_tst.csv\")\n",
    "df_loaded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aeba15-4cb8-42b1-aeb7-d7ad491e32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/bhuns/JL_2/data/ib_tst/ib_tst.csv\"\n",
    "df_ib_tst.to_csv(folder_path, index=False)\n",
    "df_ib_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cddd21-4dda-4757-aef6-b823e9b028fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded[\"Age\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0ce26-77c8-442e-ab62-60f150d7c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================================================================== Oh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74c0e6-120f-4305-bf1f-88d213250550",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa929e-64d5-42cf-aa16-51d29dc58617",
   "metadata": {},
   "source": [
    "\n",
    "# Align the columns via index suggestions from Copilot to insert new data into the major data frame\n",
    "\n",
    "Put the creation of a data frame into its own worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8af45b-1a8b-4e2e-b03b-ae1230a770fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d1773-8941-461a-8d13-e1f38b0bd09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8e79156-2206-4f99-8518-022d22456a22",
   "metadata": {},
   "source": [
    "# =============================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9231e108-6344-4293-8b02-2dbbe54de88a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Calculate the *df_ib_tst* column names from the beta column names added to the 770 column names to the 970 add column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1d6bb-026e-4f75-9f10-02715f645b57",
   "metadata": {},
   "source": [
    "## Create *df_ib_fls_tmplt* using the *df_ib_fls* column names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c1983-1804-4890-9a4c-bd1d6ed52109",
   "metadata": {},
   "source": [
    "## Then save it to pickle as df_ib_fls_tmplt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a70ecd-5016-40e4-90c3-dde43e18439c",
   "metadata": {},
   "source": [
    "## Then save it to df_ib_fls.csv  to start a new data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50aa00a-2a9c-4244-8699-03d282b28106",
   "metadata": {},
   "source": [
    "# Import the ib770 & ib970 to **df_ib_fls** These will be fill in column by column using the column name as a reference and added row by row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb21a60-6a4a-4855-bd85-597d64c2c364",
   "metadata": {},
   "source": [
    "## Import *df_ib_fls.csv*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c873d-028d-4fca-82b9-9adf037ca2ea",
   "metadata": {},
   "source": [
    "##  Import *ib97.csv and remove numbers from* And apend to *df_ib_fls* if timestamp does not exist "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3905bb-9f1c-4585-a7aa-dfd2a78085bb",
   "metadata": {},
   "source": [
    "##  Import *ib77.csv*  And apend to *df_ib_fls* if timestamp does not exist "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319453d-d438-4468-89ab-607d2498cb4c",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d9096f-7f75-4364-bd85-430bf146f882",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6685e3-b226-4fd7-8a60-0f0361baa816",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_fls_raw = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib_fls\",\n",
    "    pattern=\"*\"\n",
    ")\n",
    "df_ib_fls_raw = pd.DataFrame(ib_fls_raw)\n",
    "\n",
    "# verify\n",
    "# print( df_ib_fls_raw[\"2. ID\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866b221-0399-4163-b7ff-936b5bb6dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "# print( df_ib_fls_raw[\"2. ID\"])\n",
    "\n",
    "# df_col_nm_lst =[\"\",\"\"]\n",
    "df_col_nm_lst = pd.DataFrame( df_ib_fls_raw.columns)\n",
    "# verify\n",
    "print(df_col_nm_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12fc46-783e-4699-8470-d54e1ac3075c",
   "metadata": {},
   "source": [
    "# Remove **numbers** from col_nms   ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07513ff-b373-48f8-8e62-837f4302ccf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# STRIPS COL NMBRS  column #s from col heads\n",
    "\n",
    "def strip_col_numbers(col_names):\n",
    "    \"\"\"\n",
    "    Remove leading numbers and dots from column names.\n",
    "    Example: '244. 50kHz-Whole Body Phase Angle_Z score' \n",
    "             -> '50kHz-Whole Body Phase Angle_Z score'\n",
    "    \"\"\"\n",
    "    return [re.sub(r'^\\d+\\.\\s*', '', name) for name in col_names]\n",
    "\n",
    "# Run this for both the 970 and the 770 data imports\n",
    "# col_names = C.columns\n",
    "# df_ib_fls_raw_nm = pd.DataFrame(strip_col_numbers(col_names))\n",
    "# verify\n",
    "# print(df_ib_fls_raw_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de3c8b-6ff0-46d0-a9d3-4b12f72ddeaa",
   "metadata": {},
   "source": [
    "# Remove Duplicates so each col in 770 and 970 Have one unique Column In this overall *df_ib* dataframe   OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00d5f1-100f-45a9-a976-9cab22cc10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib_fls_raw_nm = df_ib_fls_raw_nm.drop_duplicates(keep=\"first\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38966550-936c-45c8-8053-3e25d8388a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verify\n",
    "# \n",
    "print(df_ib_fls_raw_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30916ee-0596-43d3-bc63-1c11d2e5ffdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_ib_fls_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7b35d9-431e-4640-b329-4a6d02f38ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
