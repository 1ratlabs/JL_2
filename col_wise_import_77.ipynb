{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cbb72ef-b02f-48c2-a659-88d6c3fee5e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# col_wise_import ib770 individual test results to pickle [df_mf_ib77_nn_s]\n",
    "1. ib770 exports test results to onedrive 1 csv file[uft-8] per test to ib77\n",
    "2. manual copy file to repo/data ib77\n",
    "3. import csv ib77 files to [df_ib77_raw]\n",
    "4. strips off col numbers [df_ib77_nn]\n",
    "5. Eliminate col duplicates [df_ib77_nn]\n",
    "6. adds media data cols [df_m_ib77_nn]\n",
    "7. computes media cols from data [df_mf_ib77_nn]\n",
    "8. removes timestamp duplicates to get [df_mf_ib77_nn]\n",
    "9. sorts via timestamp to get [df_mf_ib77_nn_s]\n",
    "10. writes to Pickle [df_mf_ib77_nn_s]\n",
    "11. misc functions to be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98299ccf-3813-4908-b2cb-110b5d26dd77",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc44cd5a-40d5-4bff-8dde-de21b6877ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bhuns/miniconda3/bin/python\n",
      "note: THIS IS THE DIRECTORY PYTHON IS WORKING IN.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(\"note: THIS IS THE DIRECTORY PYTHON IS WORKING IN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1c6941-4bbc-421d-bcf4-ee3bb2055a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required for Loading, sorting .csx files to create specific data sets ie mrn inbody readings. \n",
    "%run ./sys_funcs.py              # loads all the def functions in sys_funcs.py into memory\n",
    "#import sys_funcs                 # gives access to these def function digitalform that are in memory\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import time\n",
    "from sys_funcs import read_csv_to_array\n",
    "from sys_funcs import clean_wsl_path\n",
    "from sys_funcs import array_to_dt_row_dict\n",
    "from sys_funcs import make_blnk_update_row_dict\n",
    "from sys_funcs import transpose_csv_to_col_dict\n",
    "#from sys_funcs import update_values_with_config, get_update_result\n",
    "from sys_funcs import transfer_updates\n",
    "from sys_funcs import get_dtv_range\n",
    "from sys_funcs import universal_import\n",
    "from sys_funcs import parse_inbody_timestamp\n",
    "from sys_funcs import build_lut\n",
    "from sys_funcs import extract_a_column_as_df\n",
    "from sys_funcs import extract_multicolumns_as_df\n",
    "from sys_funcs import validate_and_sort_timestamps\n",
    "from sys_funcs import extract_and_filter_by_time_window\n",
    "from sys_funcs import read_file_dual_path\n",
    "from sys_funcs import write_file_dual_path\n",
    "from sys_funcs import asc_to_csv_cnv\n",
    "from collections.abc import Mapping\n",
    "import re\n",
    "#from sys_funcs import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40073c29-4be1-4d3f-86a4-f44d70c3d61f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print set to 1000 rows max\n"
     ]
    }
   ],
   "source": [
    "# set print rows  This worksheet sets maximum # of rows printed\n",
    "pd.set_option('display.max_rows', 1000)  # Adjust the number of rows to display\n",
    "# pd.reset_option('display.max_rows')  \n",
    "print('print set to 1000 rows max' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c780f0dd-0f8b-4742-9c02-a5a9512f19bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: timestamp = Test Date / Time does not work  use computed time stamp\n"
     ]
    }
   ],
   "source": [
    "print(\"NOTE: timestamp = Test Date / Time does not work  use computed time stamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acfc2e0-7d7c-44d0-8b42-b7b653431032",
   "metadata": {},
   "source": [
    "# Def functions called in data importing & refinment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad5ac93-e82e-450b-9b97-4b49dc414104",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "media_lst = [\n",
    "    \"timestamp\",\n",
    "    \"dtv\",\n",
    "    \"ib_id\",\n",
    "    \"cls\",\n",
    "    \"cmmnts\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "152dd983-4fa2-4fc8-a108-3bc04d9dea4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 3rd version def drop_duplicates_by_test_time(df, keep='first', log=True):\n",
    "def drop_duplicates_by_test_time(df, keep='first', log=True):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows based on the 'Test Date / Time' column.\n",
    "    Keeps only the first (or last) occurrence.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Identify duplicate timestamps (beyond the one we keep)\n",
    "    dupes = (\n",
    "        df.loc[df.duplicated(subset=['Test Date / Time'], keep=keep), 'Test Date / Time']\n",
    "        .astype(str)\n",
    "        .values\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates(subset=['Test Date / Time'], keep=keep)\n",
    "\n",
    "    # Optional logging\n",
    "    if log and dupes:\n",
    "        print(\"Removed duplicate rows for timestamps:\", dupes)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "952b0a1e-5cd1-4795-9378-6cc489a18932",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# RAW old def drop_duplicates_by_test_time(df, keep='first', log=True):\n",
    "\n",
    "def drop_duplicates_by_test_time(df, keep='first', log=True):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows based on the 'Test Date / Time' column.\n",
    "    Keeps only the first (or last) occurrence of each timestamp.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame.\n",
    "    keep : {'first', 'last'}, default 'first'\n",
    "        Which duplicate to keep.\n",
    "    log : bool, default True\n",
    "        Whether to print which timestamps were removed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Identify duplicate timestamps (beyond the one we keep)\n",
    "    dupes = df.loc[df.duplicated(subset=['Test Date / Time'], keep=keep),\n",
    "                   'Test Date / Time'].tolist()\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates(subset=['Test Date / Time'], keep=keep)\n",
    "\n",
    "    # Optional logging\n",
    "    if log and dupes:\n",
    "        print(\"Removed duplicate rows for timestamps:\", dupes)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73aa88c-6a17-41b0-ab8d-265ea995135d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def strip_numbers_from_columns(df):\n",
    "import re\n",
    "\n",
    "def strip_numbers_from_columns(df):\n",
    "    \"\"\"\n",
    "    Removes leading/trailing numbers and any leftover separators\n",
    "    so that cases like '1.0ID' become 'ID'.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    new_cols = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        cleaned = col\n",
    "\n",
    "        # Remove leading numbers + separators\n",
    "        cleaned = re.sub(r'^\\d+[\\s\\-\\_\\.:]*', '', cleaned)\n",
    "\n",
    "        # Remove trailing numbers + separators\n",
    "        cleaned = re.sub(r'[\\s\\-\\_\\.:]*\\d+$', '', cleaned)\n",
    "\n",
    "        # Remove leftover leading/trailing punctuation (.,-_:) after number removal\n",
    "        cleaned = re.sub(r'^[\\.\\-\\_\\:]+', '', cleaned)\n",
    "        cleaned = re.sub(r'[\\.\\-\\_\\:]+$', '', cleaned)\n",
    "\n",
    "        new_cols[col] = cleaned\n",
    "\n",
    "    return df.rename(columns=new_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eddfc987-92f4-4957-a631-a335c66df082",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Use drop duplicate function If duplicates are found\n",
    "def drop_duplicate_columns(df, keep='first', log=True):\n",
    "    \"\"\"\n",
    "    Removes duplicate column names from a DataFrame, keeping only the first\n",
    "    (or last) occurrence. Useful after column-cleaning steps that may cause\n",
    "    collisions. good i'm moving this around because I want to go ahead and do the I'm talking too\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame.\n",
    "    keep : {'first', 'last'}, default 'first'\n",
    "        Which duplicate to keep.\n",
    "    log : bool, default True\n",
    "        Whether to print which columns were removed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with duplicate columns removed.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Identify duplicates beyond the one we keep\n",
    "    dupes = df.columns[df.columns.duplicated(keep=keep)].tolist()\n",
    "\n",
    "    # Drop them\n",
    "    df = df.loc[:, ~df.columns.duplicated(keep=keep)]\n",
    "\n",
    "    # Optional logging\n",
    "    if log and dupes:\n",
    "        print(\"Removed duplicate columns:\", dupes)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a70e40-66fb-4e3a-a45e-2bb221d52eea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def prepend_empty_columns(df, col_list):\n",
    "def prepend_empty_columns(df, col_list):\n",
    "    \"\"\"\n",
    "    Prepend empty columns (from col_list) to the front of df.\n",
    "    Returns a new DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Create empty columns with same row count\n",
    "    empty_df = pd.DataFrame(\n",
    "        {col: [None] * len(df) for col in col_list}\n",
    "    )\n",
    "\n",
    "    # Prepend them\n",
    "    return pd.concat([empty_df, df], axis=1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "275e0f36-1c1c-4582-9144-f6289464ed57",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# old raw def fill_ib_media_cols(df):\n",
    "#filling the media cols\n",
    "def fill_ib_media_cols(df):\n",
    "    \"\"\"\n",
    "    Fills the 5 leading operator columns for InBody datasets:\n",
    "      - timestamp  ‚Üê parsed from 'Test Date / Time' (YYYYMMDDHHMMSS)\n",
    "      - dtv        ‚Üê days since 1900‚Äë01‚Äë01\n",
    "      - ib_id      ‚Üê 'mrn' if test time 03:00‚Äì23:59, else 'eve'\n",
    "      - cls        ‚Üê NaN\n",
    "      - cmmnts     ‚Üê NaN\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- 1. timestamp (correct parsing) ------------------------\n",
    "    df['timestamp'] = pd.to_datetime(\n",
    "        df['Test Date / Time'].astype(str),\n",
    "        format=\"%Y%m%d%H%M%S\",\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # --- 2. dtv: days since 1900‚Äë01‚Äë01 -------------------------\n",
    "    origin = pd.Timestamp(\"1900-01-01\")\n",
    "    df['dtv'] = (df['timestamp'] - origin).dt.days\n",
    "\n",
    "    # --- 3. ib_id classification -------------------------------\n",
    "    def classify_ib_id(ts):\n",
    "        if pd.isna(ts):\n",
    "            return np.nan\n",
    "        hour = ts.hour\n",
    "        return \"mrn\" if 3 <= hour <= 12 else \"eve\"\n",
    "\n",
    "    df['ib_id'] = df['timestamp'].apply(classify_ib_id)\n",
    "\n",
    "    # --- 4. cls ------------------------------------------------\n",
    "    df['cls'] = np.nan\n",
    "\n",
    "    # --- 5. cmmnts ---------------------------------------------\n",
    "    df['cmmnts'] = np.nan\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c8b4e1-7019-4f5e-8bc4-a2dbeabeb08b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# revised def fill_ib_media_cols(df):\n",
    "def fill_ib_media_cols(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- 1. Clean and parse timestamp --------------------------\n",
    "    def fix_ts(x):\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        # Convert float ‚Üí int safely\n",
    "        try:\n",
    "            x_int = int(float(x))\n",
    "        except:\n",
    "            return np.nan\n",
    "        # Zero‚Äëpad to 14 digits (YYYYMMDDHHMMSS)\n",
    "        s = str(x_int).zfill(14)\n",
    "        return pd.to_datetime(s, format=\"%Y%m%d%H%M%S\", errors=\"coerce\")\n",
    "\n",
    "    df['timestamp'] = df['Test Date / Time'].apply(fix_ts)\n",
    "\n",
    "    # --- 2. dtv ------------------------------------------------\n",
    "    origin = pd.Timestamp(\"1900-01-01\")\n",
    "    df['dtv'] = (df['timestamp'] - origin).dt.days\n",
    "\n",
    "    # --- 3. ib_id ----------------------------------------------\n",
    "    def classify_ib_id(ts):\n",
    "        if pd.isna(ts):\n",
    "            return np.nan\n",
    "        hour = ts.hour\n",
    "        return \"mrn\" if 3 <= hour <= 12 else \"eve\"\n",
    "\n",
    "    df['ib_id'] = df['timestamp'].apply(classify_ib_id)\n",
    "\n",
    "    # --- 4‚Äì5. cls, cmmnts --------------------------------------\n",
    "    df['cls'] = np.nan\n",
    "    df['cmmnts'] = np.nan\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13c4627e-8ec3-4306-8d0c-2af47e7975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the rows by timestamp\n",
    "def sort_by_timestamp(df):\n",
    "    \"\"\"\n",
    "    Sorts an InBody dataframe by the 'timestamp' column\n",
    "    in ascending chronological order.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(by='timestamp', ascending=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9b43c2-dace-4c30-beeb-97667a3f6099",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# A function to combine frames of IB77 with IB97 and sorting into one data frame. N\n",
    "# this will be used on a column by column basis for a list of columns.\n",
    "def combine_weight_frames(df_a, df_b, ts_col=\"timestamp\", wt_a=\"2. wt\", wt_b=\"4. wt\"):\n",
    "    \"\"\"\n",
    "    Combines two dataframes with different weight column names into a single\n",
    "    dataframe with columns: timestamp, wt, sorted by timestamp.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_a : pd.DataFrame\n",
    "        First dataframe containing a timestamp column and a weight column.\n",
    "    df_b : pd.DataFrame\n",
    "        Second dataframe containing a timestamp column and a weight column.\n",
    "    ts_col : str, optional\n",
    "        Name of the timestamp column (default 'timestamp').\n",
    "    wt_a : str, optional\n",
    "        Weight column name in df_a (default '2. wt').\n",
    "    wt_b : str, optional\n",
    "        Weight column name in df_b (default '4. wt').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Combined dataframe with columns: timestamp, wt, sorted by timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize df_a\n",
    "    df_a_norm = df_a[[ts_col, wt_a]].rename(columns={wt_a: \"wt\"})\n",
    "\n",
    "    # Normalize df_b\n",
    "    df_b_norm = df_b[[ts_col, wt_b]].rename(columns={wt_b: \"wt\"})\n",
    "\n",
    "    # Stack them vertically\n",
    "    df_combined = pd.concat([df_a_norm, df_b_norm], ignore_index=True)\n",
    "\n",
    "    # Sort by timestamp\n",
    "    df_combined = df_combined.sort_values(by=ts_col).reset_index(drop=True)\n",
    "\n",
    "    return df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eab1d0a-6cac-4215-91cc-b6f15049d11b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# remove duplicates on the basis of timestamp\n",
    "def remove_ib_duplicates(df, subset_cols=None):\n",
    "    \"\"\"\n",
    "    Removes duplicate InBody rows based on key identifying columns.\n",
    "    Default behavior: remove duplicates based on ['ID', 'timestamp'].\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Default duplicate definition\n",
    "    if subset_cols is None:\n",
    "        subset_cols = ['timestamp']\n",
    "        # subset_cols = ['ID', 'timestamp']\n",
    "    # Remove duplicates, keeping the first occurrence\n",
    "    df = df.drop_duplicates(subset=subset_cols, keep='first')\n",
    "\n",
    "    # Reset index for cleanliness\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6f8def7-1c3d-4df6-b53a-0d3ea6978f0e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# veirfy if rows exixt in master_timestamps(df_master, df_new, ts_col=\"timestamp\"):\n",
    "def filter_new_rows_by_master_timestamps(df_master, df_new, ts_col=\"timestamp\"):\n",
    "    \"\"\"\n",
    "    Filters df_new so that only rows whose timestamps appear in df_master remain.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_master : pd.DataFrame\n",
    "        The master dataframe containing valid timestamps.\n",
    "    df_new : pd.DataFrame\n",
    "        The new dataframe to be filtered.\n",
    "    ts_col : str, optional\n",
    "        The name of the timestamp column (default is 'timestamp').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A filtered version of df_new containing only rows whose timestamps\n",
    "        exist in df_master.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the set of valid timestamps from the master dataframe\n",
    "    valid_timestamps = set(df_master[ts_col])\n",
    "\n",
    "    # Filter df_new to keep only rows with timestamps in the master set\n",
    "    df_filtered = df_new[df_new[ts_col].isin(valid_timestamps)].copy()\n",
    "\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e2d5e7-641f-4c83-ae6a-33ea309cb874",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def keep_only_new_timestamps(df_master, df_new, ts_col=\"timestamp\")\n",
    "def keep_only_new_timestamps(df_master, df_new, ts_col=\"timestamp\"):\n",
    "    \"\"\"\n",
    "    Returns only the rows in df_new whose timestamps do NOT exist in df_master.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_master : pd.DataFrame\n",
    "        The master dataframe containing timestamps already ingested.\n",
    "    df_new : pd.DataFrame\n",
    "        The new dataframe to be filtered.\n",
    "    ts_col : str, optional\n",
    "        The name of the timestamp column (default is 'timestamp').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A filtered version of df_new containing only rows with timestamps\n",
    "        NOT present in df_master.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the set of timestamps already in the master\n",
    "    existing_ts = set(df_master[ts_col])\n",
    "\n",
    "    # Keep only rows whose timestamp is NOT in the master\n",
    "    df_filtered = df_new[~df_new[ts_col].isin(existing_ts)].copy()\n",
    "\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb376852-d4e8-4f86-813a-3b09388513fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def append_rows_with_master_schema(master_df, adder_df):\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def append_rows_with_master_schema(master_df, adder_df):\n",
    "    \"\"\"\n",
    "    Appends rows from adder_df into master_df while enforcing the master_df schema.\n",
    "\n",
    "    For each row in adder_df:\n",
    "      - Columns that exist in adder_df are copied.\n",
    "      - Columns missing from adder_df are filled with NaN.\n",
    "      - All master_df columns are preserved in order.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    master_df : pd.DataFrame\n",
    "        The master dataframe with the full schema.\n",
    "    adder_df : pd.DataFrame\n",
    "        The dataframe containing rows to append (subset of master columns).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Updated master_df with new rows appended.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reindex adder_df to match master_df columns, filling missing columns with NaN\n",
    "    adder_aligned = adder_df.reindex(columns=master_df.columns)\n",
    "\n",
    "    # Append and return\n",
    "    return pd.concat([master_df, adder_aligned], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "052ecc49-53e1-431c-8cd9-be72ca600e80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def filter_by_value(df, column, value):\n",
    "def filter_by_value(df, column, value):\n",
    "    \"\"\"\n",
    "    Returns a filtered DataFrame containing only rows where df[column] == value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to filter.\n",
    "    column : str\n",
    "        The column name to filter on.\n",
    "    value : any\n",
    "        The value that the column must match.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A filtered dataframe containing only matching rows.\n",
    "    \"\"\"\n",
    "    return df[df[column] == value].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "399b4af2-bb01-4c5c-bbc8-b10d524bafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_df_to_pickle(df, filename):\n",
    "def write_df_to_pickle(df, filename):\n",
    "    \"\"\"\n",
    "    Writes a DataFrame to a pickle file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to save.\n",
    "    filename : str\n",
    "        The pickle filename, e.g. 'mydata.pkl'.\n",
    "    \"\"\"\n",
    "    df.to_pickle(filename)\n",
    "\n",
    "# usage \n",
    "# write_df_to_pickle(df, \"df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a7611d-333d-4bd8-931b-4251d5eefada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_df_from_pickle(filename):\n",
    "\n",
    "def load_df_from_pickle(filename):\n",
    "    \"\"\"\n",
    "    Loads a DataFrame from a pickle file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the pickle file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \"\"\"\n",
    "    return pd.read_pickle(filename)\n",
    "\n",
    "    # usage \n",
    "    # df = load_df_from_pickle(\"df.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f65cee1d-c271-4489-b29a-daaeb5fa5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_mean_to_one(series):\n",
    "def scale_mean_to_one(series):\n",
    "    \"\"\"Scale a Pandas Series so that its mean becomes 1.\"\"\"\n",
    "    mean_val = series.mean()\n",
    "    return series / mean_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc4a8e1e-54bd-4261-ac7e-efca87d980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_column(df, col_name):\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_column(df, col_name):\n",
    "    \"\"\"\n",
    "    Plot a single column from a dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The dataframe containing the column.\n",
    "    col_name : str\n",
    "        The name of the column to plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(df[col_name], marker='o', linestyle='-', linewidth=1)\n",
    "    plt.title(f\"{col_name} over index\")\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(col_name)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09485323-85e1-4315-bb9a-32c5d12c0e5a",
   "metadata": {},
   "source": [
    "# Import new data from ip77 in the data folder of repo and results =  \"df_mf_ib77_nn_s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020b827-978e-400b-b6e5-60181dc345af",
   "metadata": {},
   "source": [
    "## Creating \"df_mf_ib77_nn_s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dcdaf7-bf31-4afd-8c57-2f0d3336156e",
   "metadata": {},
   "source": [
    "### This segment imports the data from the Excel file probo/data/ib77 to dataframe with numbers in col names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf019866-a3d0-4ed1-b1bb-51ecc731e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 091725_20251225081906.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251230231705.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251213054921.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251214234814.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251229081757.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251223231059.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260102235527.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251231082459.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251217075000.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251218081604.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251221071026.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260105233732.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251216233809.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251215080038.csv with utf-8\n",
      "‚úÖ Loaded 091725-1_20251212221713.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251219080729.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251221205127.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251226083412.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251227083952.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251214090336.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251230083221.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260102083939.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251218212747.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251228225544.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251224080342.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251222221501.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260102002508.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251219232758.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251215233324.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260101080305.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251227232513.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260107084153.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260106081105.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251230001616.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251224234318.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251216064808.csv with utf-8\n",
      "‚úÖ Loaded 091725-1_20251211092610.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251223082717.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260104090104.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251217230745.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260104011128.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251226232556.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251220085024.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251222083404.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251228081055.csv with utf-8\n",
      "‚úÖ Loaded 091725-1_20251212084231.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251226004351.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260103083129.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260105081107.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260104234118.csv with utf-8\n",
      "‚úÖ Loaded 091725_20251220233943.csv with utf-8\n",
      "‚úÖ Loaded 091725_20260106231913.csv with utf-8\n",
      "‚úÖ [imported_dataframe] Final DataFrame: 52 rows from 52 files.\n",
      "üíæ Saved to pickle: /home/bhuns/JL_2/imported_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "# loads the new from the 770\n",
    "df_ib77_raw = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib77\",\n",
    "    pattern=\"*\"\n",
    ")\n",
    "# verify df_ib77_raw #print(\"df_ib77_raw w/o numbers OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d29d59fe-f9aa-4dd9-817b-19eba50bfe64",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This is a test to find bad characters in the list found None\n",
    "#for col in df_ib77_raw.columns:\n",
    "#    print(repr(col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c998347-59cf-4a3c-8b0e-981719ac6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_ib77_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8af7b436-6d3f-4ae8-8483-0a3aa74be04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify list(df_ib77_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4faee3a-35af-4940-8264-da62017bb61f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This shows that the selection process skips a column\n",
    "# df_ib77_raw[\"2. ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc232acb-f3b8-4c08-9195-71f81ba9722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary This does not work because of the column skipping\n",
    "# df_ib77_raw[\"ID\"] = \"091725\"\n",
    "# verify df_ib97_raw[[\"ID\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978c848-eaf1-4e04-86c6-db9cc09dbcea",
   "metadata": {},
   "source": [
    "### This segment strips off the col names of numbers and produces \"df_m_ib77_nn\" and demonstrates slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f195eff-5777-47fd-a97b-6cf913663a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this Strips the numbers and spaces off column names and verifies the numbers are removed.\n",
    "df_ib77_nn = strip_numbers_from_columns(df_ib77_raw)\n",
    "#verify print(list(df_ib77_nn.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "206a3e44-8616-4091-bfd1-050c707a94da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There was a problem with identifying the ID column This was corrected artificially and verified slicing \n",
    "df_ib77_nn['ID']=\"091725\"\n",
    "# verify df_ib77_nn[['ID','Test Date / Time','ECW/TBW']]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96122701-c602-427a-b4af-8b2808eb14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib77_nn_s = df_ib77_nn.sort_values(by=\"Test Date / Time\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b4be4d9-aa62-48a0-980b-4cccc51a1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_ib77_nn_s[['ID','Test Date / Time','ECW/TBW']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af3666-d670-4664-8372-5b89462c01a2",
   "metadata": {},
   "source": [
    "### This segment adds **media_cols** and fills them from data in the results **\"df_m_ib77_nn\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91e7d62a-dd49-48e0-9f58-80e287745925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_ib77_nn = prepend_empty_columns(df_ib77_nn, media_lst)\n",
    "# verify df_m_ib77_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffe2c9ea-44f5-4c1b-aec9-fedfd32de66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill_ib_media_cols(df_mf_ib77_nn)\n",
    "df_mf_ib77_nn = fill_ib_media_cols(df_m_ib77_nn)\n",
    "# verify df_mf_ib77_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b0804-34ef-47f5-a0ad-b2eef09d2076",
   "metadata": {},
   "source": [
    "### This segment eliminates \"COL\" duplicates in **df_mf_ib77_nn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05a5a7a7-a3de-46cf-a25d-e49eac750de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed duplicate columns: ['Systolic', 'Diastolic', 'Pulse', 'Mean Artery Pressure', 'Pulse Pressure', 'Rate Pressure Product']\n",
      "df_mf_ib77_nn , No numbers, no duplicates OK\n"
     ]
    }
   ],
   "source": [
    "df_mf_ib77_nn = drop_duplicate_columns(df_mf_ib77_nn)\n",
    "print (\"df_mf_ib77_nn , No numbers, no duplicates OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fc599-214d-4fc3-a973-6216616b8f5a",
   "metadata": {},
   "source": [
    "### This segment sorts \"df_mf_ib77_nn\" to get \"df_mf_ib77_nn_s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "685dcb9c-b3e9-4406-86eb-6c669c7f29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_ib77_nn_s = sort_by_timestamp(df_mf_ib77_nn )\n",
    "# verify df_mf_ib77_nn_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe3891-d5b6-4863-b596-4a9e04904324",
   "metadata": {},
   "source": [
    "### This segment eliminates \"ROW\" duplicates based on **\"test_time\" in **\"df_mf_ib77_nn\"** note: \"mf\" means media added and filled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db10d754-d056-4c7b-9176-2d9ea3a9dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No timestamp duplicates **df_mf_ib77_nn** detected\n"
     ]
    }
   ],
   "source": [
    "df_mf_ib77_nn_s = df_mf_ib77_nn_s.drop_duplicates(subset=\"timestamp\", keep=\"first\")\n",
    "print(\"No timestamp duplicates **df_mf_ib77_nn** detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54b49fc0-3fc3-4884-a5a8-6843e45b2290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify list(df_mf_ib77_nn_s.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4e8e2-cd92-4e40-ac96-6a6487f37946",
   "metadata": {},
   "source": [
    "# Set the \"plt_lst\" [the list ov cols to be plotted]\n",
    "1. **\"df_mf_ib77_nn_s\"** is the source data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fbff9e7-007b-4459-9bb9-bc66627ab927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_lst = list[\"ECW/TBW\", 'BMR (Basal Metabolic Rate)',\"SMM (Skeletal Muscle Mass)\",'VFA (Visceral Fat Area)']\n",
    "# verify plt_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c2e20ca-29f2-47d3-b323-4b6dc244ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_mf_ib77_nn_s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f1f5ff3-2e62-498f-96cd-1ee56697688f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Technique for Splicing\"timestamp\" and \"a row\" from \"df_mf_ib77_nn_s\"\n",
    "# verify df_mf_ib77_nn_s[[\"timestamp\",\"ID\",\"ECW/TBW\",'BMR (Basal Metabolic Rate)',\"SMM (Skeletal Muscle Mass)\",'VFA (Visceral Fat Area)']]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff4a92c6-539c-473c-b703-ef343e8118a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ib_id</th>\n",
       "      <th>ECW/TBW</th>\n",
       "      <th>BMR (Basal Metabolic Rate)</th>\n",
       "      <th>SMM (Skeletal Muscle Mass)</th>\n",
       "      <th>VFA (Visceral Fat Area)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-11 09:26:10</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.410</td>\n",
       "      <td>2158</td>\n",
       "      <td>99.4</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-12 08:42:31</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.409</td>\n",
       "      <td>2186</td>\n",
       "      <td>101.2</td>\n",
       "      <td>162.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-12 22:17:13</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2208</td>\n",
       "      <td>101.6</td>\n",
       "      <td>158.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-13 05:49:21</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.410</td>\n",
       "      <td>2203</td>\n",
       "      <td>102.3</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-14 09:03:36</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.407</td>\n",
       "      <td>2148</td>\n",
       "      <td>99.2</td>\n",
       "      <td>167.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-14 23:48:14</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.414</td>\n",
       "      <td>2160</td>\n",
       "      <td>99.2</td>\n",
       "      <td>163.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-15 08:00:38</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.406</td>\n",
       "      <td>2155</td>\n",
       "      <td>99.9</td>\n",
       "      <td>166.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-15 23:33:24</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.413</td>\n",
       "      <td>2230</td>\n",
       "      <td>103.4</td>\n",
       "      <td>153.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-16 06:48:08</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.406</td>\n",
       "      <td>2129</td>\n",
       "      <td>98.3</td>\n",
       "      <td>167.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-16 23:38:09</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.411</td>\n",
       "      <td>2141</td>\n",
       "      <td>98.3</td>\n",
       "      <td>166.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-17 07:50:00</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.404</td>\n",
       "      <td>2141</td>\n",
       "      <td>99.4</td>\n",
       "      <td>165.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-17 23:07:45</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.407</td>\n",
       "      <td>2145</td>\n",
       "      <td>99.0</td>\n",
       "      <td>165.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-18 08:16:04</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.403</td>\n",
       "      <td>2130</td>\n",
       "      <td>98.8</td>\n",
       "      <td>169.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-18 21:27:47</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.409</td>\n",
       "      <td>2118</td>\n",
       "      <td>97.4</td>\n",
       "      <td>167.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-19 08:07:29</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2109</td>\n",
       "      <td>97.9</td>\n",
       "      <td>166.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-19 23:27:58</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.406</td>\n",
       "      <td>2148</td>\n",
       "      <td>99.4</td>\n",
       "      <td>162.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-20 08:50:24</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2089</td>\n",
       "      <td>96.8</td>\n",
       "      <td>178.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-20 23:39:43</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.409</td>\n",
       "      <td>2113</td>\n",
       "      <td>97.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-21 07:10:26</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2103</td>\n",
       "      <td>97.7</td>\n",
       "      <td>171.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-21 20:51:27</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.405</td>\n",
       "      <td>2167</td>\n",
       "      <td>100.8</td>\n",
       "      <td>161.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-22 08:34:04</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.398</td>\n",
       "      <td>2107</td>\n",
       "      <td>98.1</td>\n",
       "      <td>168.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-22 22:15:01</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.403</td>\n",
       "      <td>2101</td>\n",
       "      <td>97.0</td>\n",
       "      <td>170.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-23 08:27:17</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.398</td>\n",
       "      <td>2093</td>\n",
       "      <td>97.2</td>\n",
       "      <td>168.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-23 23:10:59</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.405</td>\n",
       "      <td>2076</td>\n",
       "      <td>95.5</td>\n",
       "      <td>175.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-24 08:03:42</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.398</td>\n",
       "      <td>2066</td>\n",
       "      <td>95.7</td>\n",
       "      <td>174.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-24 23:43:18</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.406</td>\n",
       "      <td>2088</td>\n",
       "      <td>95.9</td>\n",
       "      <td>171.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-25 08:19:06</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.399</td>\n",
       "      <td>2081</td>\n",
       "      <td>96.3</td>\n",
       "      <td>170.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-26 00:43:51</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.408</td>\n",
       "      <td>2077</td>\n",
       "      <td>95.2</td>\n",
       "      <td>170.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-26 08:34:12</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.401</td>\n",
       "      <td>2046</td>\n",
       "      <td>94.1</td>\n",
       "      <td>180.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-26 23:25:56</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.404</td>\n",
       "      <td>2093</td>\n",
       "      <td>96.6</td>\n",
       "      <td>168.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-27 08:39:52</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.398</td>\n",
       "      <td>2045</td>\n",
       "      <td>94.4</td>\n",
       "      <td>178.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-27 23:25:13</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.403</td>\n",
       "      <td>2109</td>\n",
       "      <td>97.7</td>\n",
       "      <td>166.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-28 08:10:55</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.397</td>\n",
       "      <td>2080</td>\n",
       "      <td>96.6</td>\n",
       "      <td>176.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-28 22:55:44</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.402</td>\n",
       "      <td>2116</td>\n",
       "      <td>98.1</td>\n",
       "      <td>166.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-29 08:17:57</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.398</td>\n",
       "      <td>2086</td>\n",
       "      <td>96.8</td>\n",
       "      <td>173.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-30 00:16:16</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.406</td>\n",
       "      <td>2170</td>\n",
       "      <td>101.0</td>\n",
       "      <td>160.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-30 08:32:21</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2102</td>\n",
       "      <td>97.4</td>\n",
       "      <td>171.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-30 23:17:05</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.404</td>\n",
       "      <td>2123</td>\n",
       "      <td>98.1</td>\n",
       "      <td>169.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>091725</td>\n",
       "      <td>2025-12-31 08:24:59</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.399</td>\n",
       "      <td>2083</td>\n",
       "      <td>96.6</td>\n",
       "      <td>176.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-01 08:03:05</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.401</td>\n",
       "      <td>2096</td>\n",
       "      <td>97.2</td>\n",
       "      <td>172.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-02 00:25:08</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.406</td>\n",
       "      <td>2131</td>\n",
       "      <td>98.5</td>\n",
       "      <td>165.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-02 08:39:39</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.399</td>\n",
       "      <td>2084</td>\n",
       "      <td>96.6</td>\n",
       "      <td>175.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-02 23:55:27</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.403</td>\n",
       "      <td>2120</td>\n",
       "      <td>98.3</td>\n",
       "      <td>167.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-03 08:31:29</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.398</td>\n",
       "      <td>2106</td>\n",
       "      <td>98.1</td>\n",
       "      <td>169.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-04 01:11:28</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.405</td>\n",
       "      <td>2080</td>\n",
       "      <td>95.7</td>\n",
       "      <td>173.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-04 09:01:04</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.397</td>\n",
       "      <td>2075</td>\n",
       "      <td>96.3</td>\n",
       "      <td>175.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-04 23:41:18</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.404</td>\n",
       "      <td>2095</td>\n",
       "      <td>96.8</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-05 08:11:07</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.397</td>\n",
       "      <td>2111</td>\n",
       "      <td>98.5</td>\n",
       "      <td>170.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-05 23:37:32</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.404</td>\n",
       "      <td>2162</td>\n",
       "      <td>100.8</td>\n",
       "      <td>163.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-06 08:11:05</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.397</td>\n",
       "      <td>2083</td>\n",
       "      <td>96.8</td>\n",
       "      <td>177.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-06 23:19:13</td>\n",
       "      <td>eve</td>\n",
       "      <td>0.405</td>\n",
       "      <td>2121</td>\n",
       "      <td>97.9</td>\n",
       "      <td>172.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>091725</td>\n",
       "      <td>2026-01-07 08:41:53</td>\n",
       "      <td>mrn</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2120</td>\n",
       "      <td>98.5</td>\n",
       "      <td>174.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID           timestamp ib_id  ECW/TBW  BMR (Basal Metabolic Rate)  \\\n",
       "0   091725 2025-12-11 09:26:10   mrn    0.410                        2158   \n",
       "1   091725 2025-12-12 08:42:31   mrn    0.409                        2186   \n",
       "2   091725 2025-12-12 22:17:13   eve    0.415                        2208   \n",
       "3   091725 2025-12-13 05:49:21   mrn    0.410                        2203   \n",
       "4   091725 2025-12-14 09:03:36   mrn    0.407                        2148   \n",
       "5   091725 2025-12-14 23:48:14   eve    0.414                        2160   \n",
       "6   091725 2025-12-15 08:00:38   mrn    0.406                        2155   \n",
       "7   091725 2025-12-15 23:33:24   eve    0.413                        2230   \n",
       "8   091725 2025-12-16 06:48:08   mrn    0.406                        2129   \n",
       "9   091725 2025-12-16 23:38:09   eve    0.411                        2141   \n",
       "10  091725 2025-12-17 07:50:00   mrn    0.404                        2141   \n",
       "11  091725 2025-12-17 23:07:45   eve    0.407                        2145   \n",
       "12  091725 2025-12-18 08:16:04   mrn    0.403                        2130   \n",
       "13  091725 2025-12-18 21:27:47   eve    0.409                        2118   \n",
       "14  091725 2025-12-19 08:07:29   mrn    0.400                        2109   \n",
       "15  091725 2025-12-19 23:27:58   eve    0.406                        2148   \n",
       "16  091725 2025-12-20 08:50:24   mrn    0.400                        2089   \n",
       "17  091725 2025-12-20 23:39:43   eve    0.409                        2113   \n",
       "18  091725 2025-12-21 07:10:26   mrn    0.400                        2103   \n",
       "19  091725 2025-12-21 20:51:27   eve    0.405                        2167   \n",
       "20  091725 2025-12-22 08:34:04   mrn    0.398                        2107   \n",
       "21  091725 2025-12-22 22:15:01   eve    0.403                        2101   \n",
       "22  091725 2025-12-23 08:27:17   mrn    0.398                        2093   \n",
       "23  091725 2025-12-23 23:10:59   eve    0.405                        2076   \n",
       "24  091725 2025-12-24 08:03:42   mrn    0.398                        2066   \n",
       "25  091725 2025-12-24 23:43:18   eve    0.406                        2088   \n",
       "26  091725 2025-12-25 08:19:06   mrn    0.399                        2081   \n",
       "27  091725 2025-12-26 00:43:51   eve    0.408                        2077   \n",
       "28  091725 2025-12-26 08:34:12   mrn    0.401                        2046   \n",
       "29  091725 2025-12-26 23:25:56   eve    0.404                        2093   \n",
       "30  091725 2025-12-27 08:39:52   mrn    0.398                        2045   \n",
       "31  091725 2025-12-27 23:25:13   eve    0.403                        2109   \n",
       "32  091725 2025-12-28 08:10:55   mrn    0.397                        2080   \n",
       "33  091725 2025-12-28 22:55:44   eve    0.402                        2116   \n",
       "34  091725 2025-12-29 08:17:57   mrn    0.398                        2086   \n",
       "35  091725 2025-12-30 00:16:16   eve    0.406                        2170   \n",
       "36  091725 2025-12-30 08:32:21   mrn    0.400                        2102   \n",
       "37  091725 2025-12-30 23:17:05   eve    0.404                        2123   \n",
       "38  091725 2025-12-31 08:24:59   mrn    0.399                        2083   \n",
       "39  091725 2026-01-01 08:03:05   mrn    0.401                        2096   \n",
       "40  091725 2026-01-02 00:25:08   eve    0.406                        2131   \n",
       "41  091725 2026-01-02 08:39:39   mrn    0.399                        2084   \n",
       "42  091725 2026-01-02 23:55:27   eve    0.403                        2120   \n",
       "43  091725 2026-01-03 08:31:29   mrn    0.398                        2106   \n",
       "44  091725 2026-01-04 01:11:28   eve    0.405                        2080   \n",
       "45  091725 2026-01-04 09:01:04   mrn    0.397                        2075   \n",
       "46  091725 2026-01-04 23:41:18   eve    0.404                        2095   \n",
       "47  091725 2026-01-05 08:11:07   mrn    0.397                        2111   \n",
       "48  091725 2026-01-05 23:37:32   eve    0.404                        2162   \n",
       "49  091725 2026-01-06 08:11:05   mrn    0.397                        2083   \n",
       "50  091725 2026-01-06 23:19:13   eve    0.405                        2121   \n",
       "51  091725 2026-01-07 08:41:53   mrn    0.400                        2120   \n",
       "\n",
       "    SMM (Skeletal Muscle Mass)  VFA (Visceral Fat Area)  \n",
       "0                         99.4                    167.0  \n",
       "1                        101.2                    162.7  \n",
       "2                        101.6                    158.6  \n",
       "3                        102.3                    159.8  \n",
       "4                         99.2                    167.3  \n",
       "5                         99.2                    163.1  \n",
       "6                         99.9                    166.8  \n",
       "7                        103.4                    153.1  \n",
       "8                         98.3                    167.5  \n",
       "9                         98.3                    166.4  \n",
       "10                        99.4                    165.4  \n",
       "11                        99.0                    165.1  \n",
       "12                        98.8                    169.7  \n",
       "13                        97.4                    167.6  \n",
       "14                        97.9                    166.7  \n",
       "15                        99.4                    162.3  \n",
       "16                        96.8                    178.8  \n",
       "17                        97.0                    169.0  \n",
       "18                        97.7                    171.3  \n",
       "19                       100.8                    161.3  \n",
       "20                        98.1                    168.6  \n",
       "21                        97.0                    170.5  \n",
       "22                        97.2                    168.8  \n",
       "23                        95.5                    175.9  \n",
       "24                        95.7                    174.3  \n",
       "25                        95.9                    171.9  \n",
       "26                        96.3                    170.4  \n",
       "27                        95.2                    170.9  \n",
       "28                        94.1                    180.6  \n",
       "29                        96.6                    168.9  \n",
       "30                        94.4                    178.6  \n",
       "31                        97.7                    166.9  \n",
       "32                        96.6                    176.3  \n",
       "33                        98.1                    166.4  \n",
       "34                        96.8                    173.3  \n",
       "35                       101.0                    160.4  \n",
       "36                        97.4                    171.1  \n",
       "37                        98.1                    169.4  \n",
       "38                        96.6                    176.8  \n",
       "39                        97.2                    172.8  \n",
       "40                        98.5                    165.3  \n",
       "41                        96.6                    175.7  \n",
       "42                        98.3                    167.6  \n",
       "43                        98.1                    169.9  \n",
       "44                        95.7                    173.4  \n",
       "45                        96.3                    175.8  \n",
       "46                        96.8                    173.0  \n",
       "47                        98.5                    170.1  \n",
       "48                       100.8                    163.8  \n",
       "49                        96.8                    177.8  \n",
       "50                        97.9                    172.4  \n",
       "51                        98.5                    174.1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selects the cols to be plotted \n",
    "plt_lst = [\"ECW/TBW\", 'BMR (Basal Metabolic Rate)',\"SMM (Skeletal Muscle Mass)\",'VFA (Visceral Fat Area)']\n",
    "df_mf_ib77_nn_s[[\"ID\",\"timestamp\",'ib_id']+plt_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e008e2cf-cad2-4174-9109-6f222844eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This filters out only the morning values of chosen data Col\n",
    "df_mf_ib77_nn_s_mrn = filter_by_value(df_mf_ib77_nn_s, 'ib_id', \"mrn\")\n",
    "# verify df_mf_ib77_nn_s_mrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3f63432-f9c3-435a-9392-42d7471a5f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mf_ib77_nn_s written to pickle\n"
     ]
    }
   ],
   "source": [
    "# This allows the full 77 data frame with columns to sort out for 7797 morning evening ETC\n",
    "write_df_to_pickle(df_mf_ib77_nn_s, \"df_mf_ib77_nn_s.pkl\")\n",
    "print(\"df_mf_ib77_nn_s written to pickle\")\n",
    "# verify df_mf_ib77_nn_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fc4cd7-7d2b-44d5-bd0c-b0c8644a6d62",
   "metadata": {},
   "source": [
    "# Normalize and Subract 1 on \"df_mf_ib77_nn_s[plt_lst]\" col by col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f81492-20cb-43d6-98d8-9497b6a3c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mf_ib77_nn_s_n0 = df_mf_ib77_nn_s.copy() \n",
    "df_mf_ib77_nn_s_mrn_n0 = df_mf_ib77_nn_s_mrn.copy() \n",
    "# VERIFY df_mf_ib77_nn_s_mrn_n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece8e64-0ff2-4e15-b558-913e161cbc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_col = \"ECW/TBW\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983a748-f872-4c0b-b743-de4d437f2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mf_ib77_nn_s_n0[plt_col]  =   scale_mean_to_one(df_mf_ib77_nn_s[plt_col])-1\n",
    "#df_mf_ib77_nn_s_n0[plt_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe6854-e2be-4fa2-bc1b-8af3e0cf40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_column(df_mf_ib77_nn_s_n0, plt_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecaa167-6ce3-41aa-af62-46586a010d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_lst = ['Weight',\"ECW/TBW\", 'BMR (Basal Metabolic Rate)',\"SMM (Skeletal Muscle Mass)\",'VFA (Visceral Fat Area)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1731b-19eb-48b1-a5fb-3657e8f71cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for plt_col in plt_lst:\n",
    "    print(\"Now plotting:\", plt_col)\n",
    "    df_mf_ib77_nn_s_mrn_n0[plt_col]  =   scale_mean_to_one(df_mf_ib77_nn_s_mrn[plt_col])-1\n",
    "    plot_column(df_mf_ib77_nn_s_mrn_n0, plt_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5fa8ab-9f55-4fb7-a64f-722abb54a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_column(df_mf_ib77_nn_s_n0, \"ECW/TBW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bdf6b-a514-4185-b61d-c16137e84b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41ad3678-a1c8-4cc5-94a9-ac00faa8623e",
   "metadata": {},
   "source": [
    "# WORKING cell "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
