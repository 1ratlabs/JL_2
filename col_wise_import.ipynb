{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cbb72ef-b02f-48c2-a659-88d6c3fee5e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ------ **Import Subroutines and Settings** -------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98299ccf-3813-4908-b2cb-110b5d26dd77",
   "metadata": {},
   "source": [
    "# Set up for importing data ie: **df_m_ib77_nn** to add to the main data frame **df_m_ib_tst**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc44cd5a-40d5-4bff-8dde-de21b6877ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bhuns/miniconda3/bin/python\n",
      "note: THIS IS THE DIRECTORY PYTHON IS WORKING IN.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(\"note: THIS IS THE DIRECTORY PYTHON IS WORKING IN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1c6941-4bbc-421d-bcf4-ee3bb2055a94",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports required for Loading, sorting .csx files to create specific data sets ie mrn inbody readings. \n",
    "%run ./sys_funcs.py              # loads all the def functions in sys_funcs.py into memory\n",
    "#import sys_funcs                 # gives access to these def function digitalform that are in memory\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import time\n",
    "from sys_funcs import read_csv_to_array\n",
    "from sys_funcs import clean_wsl_path\n",
    "from sys_funcs import array_to_dt_row_dict\n",
    "from sys_funcs import make_blnk_update_row_dict\n",
    "from sys_funcs import transpose_csv_to_col_dict\n",
    "#from sys_funcs import update_values_with_config, get_update_result\n",
    "from sys_funcs import transfer_updates\n",
    "from sys_funcs import get_dtv_range\n",
    "from sys_funcs import universal_import\n",
    "from sys_funcs import parse_inbody_timestamp\n",
    "from sys_funcs import build_lut\n",
    "from sys_funcs import extract_a_column_as_df\n",
    "from sys_funcs import extract_multicolumns_as_df\n",
    "from sys_funcs import validate_and_sort_timestamps\n",
    "from sys_funcs import extract_and_filter_by_time_window\n",
    "from sys_funcs import read_file_dual_path\n",
    "from sys_funcs import write_file_dual_path\n",
    "from sys_funcs import asc_to_csv_cnv\n",
    "from collections.abc import Mapping\n",
    "import re\n",
    "#from sys_funcs import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40073c29-4be1-4d3f-86a4-f44d70c3d61f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print set to 1000 rows max\n"
     ]
    }
   ],
   "source": [
    "# set print rows  This worksheet sets maximum # of rows printed\n",
    "pd.set_option('display.max_rows', 1000)  # Adjust the number of rows to display\n",
    "# pd.reset_option('display.max_rows')  \n",
    "print('print set to 1000 rows max' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c780f0dd-0f8b-4742-9c02-a5a9512f19bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: timestamp = Test Date / Time does not work  use computed time stamp\n"
     ]
    }
   ],
   "source": [
    "print(\"NOTE: timestamp = Test Date / Time does not work  use computed time stamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d9746-4c03-45ae-be07-78979b22db00",
   "metadata": {},
   "source": [
    "# Pre-concatinate processing import and prepare \n",
    "1. **\"df_m_ib_tst\"**\n",
    "2. **\"df_m_ib77_nn\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acfc2e0-7d7c-44d0-8b42-b7b653431032",
   "metadata": {},
   "source": [
    "## def functions called in data importing & refinment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad5ac93-e82e-450b-9b97-4b49dc414104",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_lst = [\n",
    "    \"Test Date / Time\",\n",
    "    \"timestamp\",\n",
    "    \"dtv\",\n",
    "    \"ib_id\",\n",
    "    \"cls\",\n",
    "    \"cmmnts\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "152dd983-4fa2-4fc8-a108-3bc04d9dea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd version def drop_duplicates_by_test_time(df, keep='first', log=True):\n",
    "def drop_duplicates_by_test_time(df, keep='first', log=True):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows based on the 'Test Date / Time' column.\n",
    "    Keeps only the first (or last) occurrence.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Identify duplicate timestamps (beyond the one we keep)\n",
    "    dupes = (\n",
    "        df.loc[df.duplicated(subset=['Test Date / Time'], keep=keep), 'Test Date / Time']\n",
    "        .astype(str)\n",
    "        .values\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates(subset=['Test Date / Time'], keep=keep)\n",
    "\n",
    "    # Optional logging\n",
    "    if log and dupes:\n",
    "        print(\"Removed duplicate rows for timestamps:\", dupes)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "952b0a1e-5cd1-4795-9378-6cc489a18932",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# def drop_duplicates_by_test_time(df, keep='first', log=True):\n",
    "\n",
    "def drop_duplicates_by_test_time(df, keep='first', log=True):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows based on the 'Test Date / Time' column.\n",
    "    Keeps only the first (or last) occurrence of each timestamp.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame.\n",
    "    keep : {'first', 'last'}, default 'first'\n",
    "        Which duplicate to keep.\n",
    "    log : bool, default True\n",
    "        Whether to print which timestamps were removed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Identify duplicate timestamps (beyond the one we keep)\n",
    "    dupes = df.loc[df.duplicated(subset=['Test Date / Time'], keep=keep),\n",
    "                   'Test Date / Time'].tolist()\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates(subset=['Test Date / Time'], keep=keep)\n",
    "\n",
    "    # Optional logging\n",
    "    if log and dupes:\n",
    "        print(\"Removed duplicate rows for timestamps:\", dupes)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73aa88c-6a17-41b0-ab8d-265ea995135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def strip_numbers_from_columns(df):\n",
    "import re\n",
    "\n",
    "def strip_numbers_from_columns(df):\n",
    "    \"\"\"\n",
    "    Removes leading/trailing numbers and any leftover separators\n",
    "    so that cases like '1.0ID' become 'ID'.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    new_cols = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        cleaned = col\n",
    "\n",
    "        # Remove leading numbers + separators\n",
    "        cleaned = re.sub(r'^\\d+[\\s\\-\\_\\.:]*', '', cleaned)\n",
    "\n",
    "        # Remove trailing numbers + separators\n",
    "        cleaned = re.sub(r'[\\s\\-\\_\\.:]*\\d+$', '', cleaned)\n",
    "\n",
    "        # Remove leftover leading/trailing punctuation (.,-_:) after number removal\n",
    "        cleaned = re.sub(r'^[\\.\\-\\_\\:]+', '', cleaned)\n",
    "        cleaned = re.sub(r'[\\.\\-\\_\\:]+$', '', cleaned)\n",
    "\n",
    "        new_cols[col] = cleaned\n",
    "\n",
    "    return df.rename(columns=new_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eddfc987-92f4-4957-a631-a335c66df082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use drop duplicate function If duplicates are found\n",
    "def drop_duplicate_columns(df, keep='first', log=True):\n",
    "    \"\"\"\n",
    "    Removes duplicate column names from a DataFrame, keeping only the first\n",
    "    (or last) occurrence. Useful after column-cleaning steps that may cause\n",
    "    collisions. good i'm moving this around because I want to go ahead and do the I'm talking too\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame.\n",
    "    keep : {'first', 'last'}, default 'first'\n",
    "        Which duplicate to keep.\n",
    "    log : bool, default True\n",
    "        Whether to print which columns were removed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with duplicate columns removed.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Identify duplicates beyond the one we keep\n",
    "    dupes = df.columns[df.columns.duplicated(keep=keep)].tolist()\n",
    "\n",
    "    # Drop them\n",
    "    df = df.loc[:, ~df.columns.duplicated(keep=keep)]\n",
    "\n",
    "    # Optional logging\n",
    "    if log and dupes:\n",
    "        print(\"Removed duplicate columns:\", dupes)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a70e40-66fb-4e3a-a45e-2bb221d52eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepend_empty_columns(df, col_list):\n",
    "def prepend_empty_columns(df, col_list):\n",
    "    \"\"\"\n",
    "    Prepend empty columns (from col_list) to the front of df.\n",
    "    Returns a new DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Create empty columns with same row count\n",
    "    empty_df = pd.DataFrame(\n",
    "        {col: [None] * len(df) for col in col_list}\n",
    "    )\n",
    "\n",
    "    # Prepend them\n",
    "    return pd.concat([empty_df, df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "275e0f36-1c1c-4582-9144-f6289464ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fill_ib_media_cols(df):\n",
    "#filling the media cols\n",
    "def fill_ib_media_cols(df):\n",
    "    \"\"\"\n",
    "    Fills the 5 leading operator columns for InBody datasets:\n",
    "      - timestamp  ← parsed from 'Test Date / Time' (YYYYMMDDHHMMSS)\n",
    "      - dtv        ← days since 1900‑01‑01\n",
    "      - ib_id      ← 'mrn' if test time 03:00–23:59, else 'eve'\n",
    "      - cls        ← NaN\n",
    "      - cmmnts     ← NaN\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- 1. timestamp (correct parsing) ------------------------\n",
    "    df['timestamp'] = pd.to_datetime(\n",
    "        df['Test Date / Time'].astype(str),\n",
    "        format=\"%Y%m%d%H%M%S\",\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # --- 2. dtv: days since 1900‑01‑01 -------------------------\n",
    "    origin = pd.Timestamp(\"1900-01-01\")\n",
    "    df['dtv'] = (df['timestamp'] - origin).dt.days\n",
    "\n",
    "    # --- 3. ib_id classification -------------------------------\n",
    "    def classify_ib_id(ts):\n",
    "        if pd.isna(ts):\n",
    "            return np.nan\n",
    "        hour = ts.hour\n",
    "        return \"mrn\" if 3 <= hour <= 12 else \"eve\"\n",
    "\n",
    "    df['ib_id'] = df['timestamp'].apply(classify_ib_id)\n",
    "\n",
    "    # --- 4. cls ------------------------------------------------\n",
    "    df['cls'] = np.nan\n",
    "\n",
    "    # --- 5. cmmnts ---------------------------------------------\n",
    "    df['cmmnts'] = np.nan\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13c4627e-8ec3-4306-8d0c-2af47e7975d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the rows by timestamp\n",
    "def sort_by_timestamp(df):\n",
    "    \"\"\"\n",
    "    Sorts an InBody dataframe by the 'timestamp' column\n",
    "    in ascending chronological order.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(by='timestamp', ascending=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eab1d0a-6cac-4215-91cc-b6f15049d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates on the basis of timestamp\n",
    "def remove_ib_duplicates(df, subset_cols=None):\n",
    "    \"\"\"\n",
    "    Removes duplicate InBody rows based on key identifying columns.\n",
    "    Default behavior: remove duplicates based on ['ID', 'timestamp'].\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Default duplicate definition\n",
    "    if subset_cols is None:\n",
    "        subset_cols = ['timestamp']\n",
    "        # subset_cols = ['ID', 'timestamp']\n",
    "    # Remove duplicates, keeping the first occurrence\n",
    "    df = df.drop_duplicates(subset=subset_cols, keep='first')\n",
    "\n",
    "    # Reset index for cleanliness\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89edf483-5b5e-4433-9af2-e59c4016acac",
   "metadata": {},
   "source": [
    "# UPDATE **\"df_m_ib_tst\"** with latest data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d96c0c-03ff-4d1a-9906-8d79b9023457",
   "metadata": {},
   "source": [
    "## Bringing in the main data file from Excel and produce clean **df_m_ib_tst_nn** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d558912-723b-45b4-aedb-9961ec71bebf",
   "metadata": {},
   "source": [
    "### load from XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "721664be-06f6-4bbb-a03d-9c530f86929a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported **df_m_ib_tst_nn** ie numbers removed from col heads\n"
     ]
    }
   ],
   "source": [
    "#this brings in the main data file from Excel\n",
    "df_m_ib_tst = pd.read_csv(\"/home/bhuns/JL_2/data/ib_tst/m_ib_tst.csv\")\n",
    "df_m_ib_tst_nn = strip_numbers_from_columns(df_m_ib_tst)\n",
    "# verify \n",
    "df_m_ib_tst_nn\n",
    "print(\"imported **df_m_ib_tst_nn** ie numbers removed from col heads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2239bf-4757-4249-a282-d04ceda88292",
   "metadata": {},
   "source": [
    "### Insure no numbers in col names & slice-abilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc27f5f7-b5d4-4f84-b801-8653e9f14c84",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_m_ib_tst_nn imported \n",
      " Test Date / Time \n",
      " 0     20251213054921\n",
      "1     20251214234814\n",
      "2     20251217075000\n",
      "3     20251218081604\n",
      "4     20251216233809\n",
      "5     20251215080038\n",
      "6     20251212221713\n",
      "7     20251219080729\n",
      "8     20251214090336\n",
      "9     20251218212747\n",
      "10    20251219232758\n",
      "11    20251215233324\n",
      "12    20251216064808\n",
      "13    20251211092610\n",
      "14    20251217230745\n",
      "15    20251220085024\n",
      "16    20251212084231\n",
      "17    20251213054921\n",
      "18    20251214234814\n",
      "19    20251217075000\n",
      "20    20251218081604\n",
      "21    20251216233809\n",
      "22    20251215080038\n",
      "23    20251212221713\n",
      "24    20251219080729\n",
      "25    20251214090336\n",
      "26    20251218212747\n",
      "27    20251219232758\n",
      "28    20251215233324\n",
      "29    20251216064808\n",
      "30    20251211092610\n",
      "31    20251217230745\n",
      "32    20251220085024\n",
      "33    20251212084231\n",
      "34    20251213054921\n",
      "35    20251214234814\n",
      "36    20251217075000\n",
      "37    20251218081604\n",
      "38    20251216233809\n",
      "39    20251215080038\n",
      "40    20251212221713\n",
      "41    20251219080729\n",
      "42    20251214090336\n",
      "43    20251218212747\n",
      "44    20251219232758\n",
      "45    20251215233324\n",
      "46    20251216064808\n",
      "47    20251211092610\n",
      "48    20251217230745\n",
      "49    20251220085024\n",
      "50    20251212084231\n",
      "51    20250922225826\n",
      "Name: Test Date / Time, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df_m_ib_tst_nn slicing\n",
    "# verify \n",
    "print('df_m_ib_tst_nn imported \\n Test Date / Time \\n',df_m_ib_tst_nn['Test Date / Time'])  # list form wo meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcddc4ef-0270-4ad8-9799-9814f52a7cda",
   "metadata": {},
   "source": [
    "### Insure that media_lst cols inserted in **df_m_ib_tst_nn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddfc36dd-d2ec-44d6-bc20-4f71ecb665f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Date / Time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>dtv</th>\n",
       "      <th>ib_id</th>\n",
       "      <th>cls</th>\n",
       "      <th>cmmnts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251213054921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251214234814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251217075000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251218081604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251216233809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251215080038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251212221713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251219080729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251214090336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251218212747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251219232758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251215233324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251216064808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251211092610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251217230745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251220085024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251212084231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251213054921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251214234814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251217075000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251218081604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251216233809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251215080038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251212221713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251219080729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251214090336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251218212747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251219232758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251215233324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251216064808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251211092610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251217230745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251220085024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251212084231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251213054921</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251214234814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251217075000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251218081604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251216233809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251215080038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251212221713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20251219080729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20251214090336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20251218212747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20251219232758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20251215233324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20251216064808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20251211092610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20251217230745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>20251220085024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>20251212084231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>20250922225826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Date / Time  timestamp  dtv  ib_id  cls  cmmnts\n",
       "0     20251213054921        NaN  NaN    NaN  NaN     NaN\n",
       "1     20251214234814        NaN  NaN    NaN  NaN     NaN\n",
       "2     20251217075000        NaN  NaN    NaN  NaN     NaN\n",
       "3     20251218081604        NaN  NaN    NaN  NaN     NaN\n",
       "4     20251216233809        NaN  NaN    NaN  NaN     NaN\n",
       "5     20251215080038        NaN  NaN    NaN  NaN     NaN\n",
       "6     20251212221713        NaN  NaN    NaN  NaN     NaN\n",
       "7     20251219080729        NaN  NaN    NaN  NaN     NaN\n",
       "8     20251214090336        NaN  NaN    NaN  NaN     NaN\n",
       "9     20251218212747        NaN  NaN    NaN  NaN     NaN\n",
       "10    20251219232758        NaN  NaN    NaN  NaN     NaN\n",
       "11    20251215233324        NaN  NaN    NaN  NaN     NaN\n",
       "12    20251216064808        NaN  NaN    NaN  NaN     NaN\n",
       "13    20251211092610        NaN  NaN    NaN  NaN     NaN\n",
       "14    20251217230745        NaN  NaN    NaN  NaN     NaN\n",
       "15    20251220085024        NaN  NaN    NaN  NaN     NaN\n",
       "16    20251212084231        NaN  NaN    NaN  NaN     NaN\n",
       "17    20251213054921        NaN  NaN    NaN  NaN     NaN\n",
       "18    20251214234814        NaN  NaN    NaN  NaN     NaN\n",
       "19    20251217075000        NaN  NaN    NaN  NaN     NaN\n",
       "20    20251218081604        NaN  NaN    NaN  NaN     NaN\n",
       "21    20251216233809        NaN  NaN    NaN  NaN     NaN\n",
       "22    20251215080038        NaN  NaN    NaN  NaN     NaN\n",
       "23    20251212221713        NaN  NaN    NaN  NaN     NaN\n",
       "24    20251219080729        NaN  NaN    NaN  NaN     NaN\n",
       "25    20251214090336        NaN  NaN    NaN  NaN     NaN\n",
       "26    20251218212747        NaN  NaN    NaN  NaN     NaN\n",
       "27    20251219232758        NaN  NaN    NaN  NaN     NaN\n",
       "28    20251215233324        NaN  NaN    NaN  NaN     NaN\n",
       "29    20251216064808        NaN  NaN    NaN  NaN     NaN\n",
       "30    20251211092610        NaN  NaN    NaN  NaN     NaN\n",
       "31    20251217230745        NaN  NaN    NaN  NaN     NaN\n",
       "32    20251220085024        NaN  NaN    NaN  NaN     NaN\n",
       "33    20251212084231        NaN  NaN    NaN  NaN     NaN\n",
       "34    20251213054921        NaN  NaN    NaN  NaN     NaN\n",
       "35    20251214234814        NaN  NaN    NaN  NaN     NaN\n",
       "36    20251217075000        NaN  NaN    NaN  NaN     NaN\n",
       "37    20251218081604        NaN  NaN    NaN  NaN     NaN\n",
       "38    20251216233809        NaN  NaN    NaN  NaN     NaN\n",
       "39    20251215080038        NaN  NaN    NaN  NaN     NaN\n",
       "40    20251212221713        NaN  NaN    NaN  NaN     NaN\n",
       "41    20251219080729        NaN  NaN    NaN  NaN     NaN\n",
       "42    20251214090336        NaN  NaN    NaN  NaN     NaN\n",
       "43    20251218212747        NaN  NaN    NaN  NaN     NaN\n",
       "44    20251219232758        NaN  NaN    NaN  NaN     NaN\n",
       "45    20251215233324        NaN  NaN    NaN  NaN     NaN\n",
       "46    20251216064808        NaN  NaN    NaN  NaN     NaN\n",
       "47    20251211092610        NaN  NaN    NaN  NaN     NaN\n",
       "48    20251217230745        NaN  NaN    NaN  NaN     NaN\n",
       "49    20251220085024        NaN  NaN    NaN  NaN     NaN\n",
       "50    20251212084231        NaN  NaN    NaN  NaN     NaN\n",
       "51    20250922225826        NaN  NaN    NaN  NaN     NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify \n",
    "df_m_ib_tst_nn[media_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608180a7-fb59-45e4-b680-9af43c950e82",
   "metadata": {},
   "source": [
    "### Insure that media_lst cols are filled in **df_m_ib_tst_nn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65bd028d-8aed-4a63-80ff-5ab8b3212be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Date / Time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>dtv</th>\n",
       "      <th>ib_id</th>\n",
       "      <th>cls</th>\n",
       "      <th>cmmnts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251213054921</td>\n",
       "      <td>2025-12-13 05:49:21</td>\n",
       "      <td>46002</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251214234814</td>\n",
       "      <td>2025-12-14 23:48:14</td>\n",
       "      <td>46003</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251217075000</td>\n",
       "      <td>2025-12-17 07:50:00</td>\n",
       "      <td>46006</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251218081604</td>\n",
       "      <td>2025-12-18 08:16:04</td>\n",
       "      <td>46007</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251216233809</td>\n",
       "      <td>2025-12-16 23:38:09</td>\n",
       "      <td>46005</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251215080038</td>\n",
       "      <td>2025-12-15 08:00:38</td>\n",
       "      <td>46004</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251212221713</td>\n",
       "      <td>2025-12-12 22:17:13</td>\n",
       "      <td>46001</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251219080729</td>\n",
       "      <td>2025-12-19 08:07:29</td>\n",
       "      <td>46008</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251214090336</td>\n",
       "      <td>2025-12-14 09:03:36</td>\n",
       "      <td>46003</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251218212747</td>\n",
       "      <td>2025-12-18 21:27:47</td>\n",
       "      <td>46007</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251219232758</td>\n",
       "      <td>2025-12-19 23:27:58</td>\n",
       "      <td>46008</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251215233324</td>\n",
       "      <td>2025-12-15 23:33:24</td>\n",
       "      <td>46004</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251216064808</td>\n",
       "      <td>2025-12-16 06:48:08</td>\n",
       "      <td>46005</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251211092610</td>\n",
       "      <td>2025-12-11 09:26:10</td>\n",
       "      <td>46000</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251217230745</td>\n",
       "      <td>2025-12-17 23:07:45</td>\n",
       "      <td>46006</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251220085024</td>\n",
       "      <td>2025-12-20 08:50:24</td>\n",
       "      <td>46009</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251212084231</td>\n",
       "      <td>2025-12-12 08:42:31</td>\n",
       "      <td>46001</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251213054921</td>\n",
       "      <td>2025-12-13 05:49:21</td>\n",
       "      <td>46002</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251214234814</td>\n",
       "      <td>2025-12-14 23:48:14</td>\n",
       "      <td>46003</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251217075000</td>\n",
       "      <td>2025-12-17 07:50:00</td>\n",
       "      <td>46006</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251218081604</td>\n",
       "      <td>2025-12-18 08:16:04</td>\n",
       "      <td>46007</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251216233809</td>\n",
       "      <td>2025-12-16 23:38:09</td>\n",
       "      <td>46005</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251215080038</td>\n",
       "      <td>2025-12-15 08:00:38</td>\n",
       "      <td>46004</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251212221713</td>\n",
       "      <td>2025-12-12 22:17:13</td>\n",
       "      <td>46001</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251219080729</td>\n",
       "      <td>2025-12-19 08:07:29</td>\n",
       "      <td>46008</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251214090336</td>\n",
       "      <td>2025-12-14 09:03:36</td>\n",
       "      <td>46003</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251218212747</td>\n",
       "      <td>2025-12-18 21:27:47</td>\n",
       "      <td>46007</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251219232758</td>\n",
       "      <td>2025-12-19 23:27:58</td>\n",
       "      <td>46008</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251215233324</td>\n",
       "      <td>2025-12-15 23:33:24</td>\n",
       "      <td>46004</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251216064808</td>\n",
       "      <td>2025-12-16 06:48:08</td>\n",
       "      <td>46005</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251211092610</td>\n",
       "      <td>2025-12-11 09:26:10</td>\n",
       "      <td>46000</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251217230745</td>\n",
       "      <td>2025-12-17 23:07:45</td>\n",
       "      <td>46006</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251220085024</td>\n",
       "      <td>2025-12-20 08:50:24</td>\n",
       "      <td>46009</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251212084231</td>\n",
       "      <td>2025-12-12 08:42:31</td>\n",
       "      <td>46001</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251213054921</td>\n",
       "      <td>2025-12-13 05:49:21</td>\n",
       "      <td>46002</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251214234814</td>\n",
       "      <td>2025-12-14 23:48:14</td>\n",
       "      <td>46003</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251217075000</td>\n",
       "      <td>2025-12-17 07:50:00</td>\n",
       "      <td>46006</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251218081604</td>\n",
       "      <td>2025-12-18 08:16:04</td>\n",
       "      <td>46007</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251216233809</td>\n",
       "      <td>2025-12-16 23:38:09</td>\n",
       "      <td>46005</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251215080038</td>\n",
       "      <td>2025-12-15 08:00:38</td>\n",
       "      <td>46004</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251212221713</td>\n",
       "      <td>2025-12-12 22:17:13</td>\n",
       "      <td>46001</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20251219080729</td>\n",
       "      <td>2025-12-19 08:07:29</td>\n",
       "      <td>46008</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20251214090336</td>\n",
       "      <td>2025-12-14 09:03:36</td>\n",
       "      <td>46003</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20251218212747</td>\n",
       "      <td>2025-12-18 21:27:47</td>\n",
       "      <td>46007</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20251219232758</td>\n",
       "      <td>2025-12-19 23:27:58</td>\n",
       "      <td>46008</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20251215233324</td>\n",
       "      <td>2025-12-15 23:33:24</td>\n",
       "      <td>46004</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20251216064808</td>\n",
       "      <td>2025-12-16 06:48:08</td>\n",
       "      <td>46005</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20251211092610</td>\n",
       "      <td>2025-12-11 09:26:10</td>\n",
       "      <td>46000</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20251217230745</td>\n",
       "      <td>2025-12-17 23:07:45</td>\n",
       "      <td>46006</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>20251220085024</td>\n",
       "      <td>2025-12-20 08:50:24</td>\n",
       "      <td>46009</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>20251212084231</td>\n",
       "      <td>2025-12-12 08:42:31</td>\n",
       "      <td>46001</td>\n",
       "      <td>mrn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>20250922225826</td>\n",
       "      <td>2025-09-22 22:58:26</td>\n",
       "      <td>45920</td>\n",
       "      <td>eve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Test Date / Time           timestamp    dtv ib_id  cls  cmmnts\n",
       "0     20251213054921 2025-12-13 05:49:21  46002   mrn  NaN     NaN\n",
       "1     20251214234814 2025-12-14 23:48:14  46003   eve  NaN     NaN\n",
       "2     20251217075000 2025-12-17 07:50:00  46006   mrn  NaN     NaN\n",
       "3     20251218081604 2025-12-18 08:16:04  46007   mrn  NaN     NaN\n",
       "4     20251216233809 2025-12-16 23:38:09  46005   eve  NaN     NaN\n",
       "5     20251215080038 2025-12-15 08:00:38  46004   mrn  NaN     NaN\n",
       "6     20251212221713 2025-12-12 22:17:13  46001   eve  NaN     NaN\n",
       "7     20251219080729 2025-12-19 08:07:29  46008   mrn  NaN     NaN\n",
       "8     20251214090336 2025-12-14 09:03:36  46003   mrn  NaN     NaN\n",
       "9     20251218212747 2025-12-18 21:27:47  46007   eve  NaN     NaN\n",
       "10    20251219232758 2025-12-19 23:27:58  46008   eve  NaN     NaN\n",
       "11    20251215233324 2025-12-15 23:33:24  46004   eve  NaN     NaN\n",
       "12    20251216064808 2025-12-16 06:48:08  46005   mrn  NaN     NaN\n",
       "13    20251211092610 2025-12-11 09:26:10  46000   mrn  NaN     NaN\n",
       "14    20251217230745 2025-12-17 23:07:45  46006   eve  NaN     NaN\n",
       "15    20251220085024 2025-12-20 08:50:24  46009   mrn  NaN     NaN\n",
       "16    20251212084231 2025-12-12 08:42:31  46001   mrn  NaN     NaN\n",
       "17    20251213054921 2025-12-13 05:49:21  46002   mrn  NaN     NaN\n",
       "18    20251214234814 2025-12-14 23:48:14  46003   eve  NaN     NaN\n",
       "19    20251217075000 2025-12-17 07:50:00  46006   mrn  NaN     NaN\n",
       "20    20251218081604 2025-12-18 08:16:04  46007   mrn  NaN     NaN\n",
       "21    20251216233809 2025-12-16 23:38:09  46005   eve  NaN     NaN\n",
       "22    20251215080038 2025-12-15 08:00:38  46004   mrn  NaN     NaN\n",
       "23    20251212221713 2025-12-12 22:17:13  46001   eve  NaN     NaN\n",
       "24    20251219080729 2025-12-19 08:07:29  46008   mrn  NaN     NaN\n",
       "25    20251214090336 2025-12-14 09:03:36  46003   mrn  NaN     NaN\n",
       "26    20251218212747 2025-12-18 21:27:47  46007   eve  NaN     NaN\n",
       "27    20251219232758 2025-12-19 23:27:58  46008   eve  NaN     NaN\n",
       "28    20251215233324 2025-12-15 23:33:24  46004   eve  NaN     NaN\n",
       "29    20251216064808 2025-12-16 06:48:08  46005   mrn  NaN     NaN\n",
       "30    20251211092610 2025-12-11 09:26:10  46000   mrn  NaN     NaN\n",
       "31    20251217230745 2025-12-17 23:07:45  46006   eve  NaN     NaN\n",
       "32    20251220085024 2025-12-20 08:50:24  46009   mrn  NaN     NaN\n",
       "33    20251212084231 2025-12-12 08:42:31  46001   mrn  NaN     NaN\n",
       "34    20251213054921 2025-12-13 05:49:21  46002   mrn  NaN     NaN\n",
       "35    20251214234814 2025-12-14 23:48:14  46003   eve  NaN     NaN\n",
       "36    20251217075000 2025-12-17 07:50:00  46006   mrn  NaN     NaN\n",
       "37    20251218081604 2025-12-18 08:16:04  46007   mrn  NaN     NaN\n",
       "38    20251216233809 2025-12-16 23:38:09  46005   eve  NaN     NaN\n",
       "39    20251215080038 2025-12-15 08:00:38  46004   mrn  NaN     NaN\n",
       "40    20251212221713 2025-12-12 22:17:13  46001   eve  NaN     NaN\n",
       "41    20251219080729 2025-12-19 08:07:29  46008   mrn  NaN     NaN\n",
       "42    20251214090336 2025-12-14 09:03:36  46003   mrn  NaN     NaN\n",
       "43    20251218212747 2025-12-18 21:27:47  46007   eve  NaN     NaN\n",
       "44    20251219232758 2025-12-19 23:27:58  46008   eve  NaN     NaN\n",
       "45    20251215233324 2025-12-15 23:33:24  46004   eve  NaN     NaN\n",
       "46    20251216064808 2025-12-16 06:48:08  46005   mrn  NaN     NaN\n",
       "47    20251211092610 2025-12-11 09:26:10  46000   mrn  NaN     NaN\n",
       "48    20251217230745 2025-12-17 23:07:45  46006   eve  NaN     NaN\n",
       "49    20251220085024 2025-12-20 08:50:24  46009   mrn  NaN     NaN\n",
       "50    20251212084231 2025-12-12 08:42:31  46001   mrn  NaN     NaN\n",
       "51    20250922225826 2025-09-22 22:58:26  45920   eve  NaN     NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill_ib_media_cols(df_m_ib_tst_nn)\n",
    "df_m_ib_tst_nn = fill_ib_media_cols(df_m_ib_tst_nn)\n",
    "# verify \n",
    "df_m_ib_tst_nn[media_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09485323-85e1-4315-bb9a-32c5d12c0e5a",
   "metadata": {},
   "source": [
    "## Import new data from ip77 in the data folder of repo and produce clean rows ready to concatinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dcdaf7-bf31-4afd-8c57-2f0d3336156e",
   "metadata": {},
   "source": [
    "### This segment imports the data from the Excel file_ib77 to dataframe with numbers in col names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf019866-a3d0-4ed1-b1bb-51ecc731e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 091725_20251225081906.csv with utf-8\n",
      "✅ Loaded 091725_20251213054921.csv with utf-8\n",
      "✅ Loaded 091725_20251214234814.csv with utf-8\n",
      "✅ Loaded 091725_20251223231059.csv with utf-8\n",
      "✅ Loaded 091725_20251217075000.csv with utf-8\n",
      "✅ Loaded 091725_20251218081604.csv with utf-8\n",
      "✅ Loaded 091725_20251221071026.csv with utf-8\n",
      "✅ Loaded 091725_20251216233809.csv with utf-8\n",
      "✅ Loaded 091725_20251215080038.csv with utf-8\n",
      "✅ Loaded 091725-1_20251212221713.csv with utf-8\n",
      "✅ Loaded 091725_20251219080729.csv with utf-8\n",
      "✅ Loaded 091725_20251221205127.csv with utf-8\n",
      "✅ Loaded 091725_20251226083412.csv with utf-8\n",
      "✅ Loaded 091725_20251227083952.csv with utf-8\n",
      "✅ Loaded 091725_20251214090336.csv with utf-8\n",
      "✅ Loaded 091725_20251218212747.csv with utf-8\n",
      "✅ Loaded 091725_20251224080342.csv with utf-8\n",
      "✅ Loaded 091725_20251222221501.csv with utf-8\n",
      "✅ Loaded 091725_20251219232758.csv with utf-8\n",
      "✅ Loaded 091725_20251215233324.csv with utf-8\n",
      "✅ Loaded 091725_20251224234318.csv with utf-8\n",
      "✅ Loaded 091725_20251216064808.csv with utf-8\n",
      "✅ Loaded 091725-1_20251211092610.csv with utf-8\n",
      "✅ Loaded 091725_20251223082717.csv with utf-8\n",
      "✅ Loaded 091725_20251217230745.csv with utf-8\n",
      "✅ Loaded 091725_20251226232556.csv with utf-8\n",
      "✅ Loaded 091725_20251220085024.csv with utf-8\n",
      "✅ Loaded 091725_20251222083404.csv with utf-8\n",
      "✅ Loaded 091725-1_20251212084231.csv with utf-8\n",
      "✅ Loaded 091725_20251226004351.csv with utf-8\n",
      "✅ Loaded 091725_20251220233943.csv with utf-8\n",
      "✅ [imported_dataframe] Final DataFrame: 31 rows from 31 files.\n",
      "💾 Saved to pickle: /home/bhuns/JL_2/imported_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "# loads the new from the 770\n",
    "df_ib77_raw = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib77\",\n",
    "    pattern=\"*\"\n",
    ")\n",
    "# verify df_ib77_raw #print(\"df_ib77_raw w/o numbers OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978c848-eaf1-4e04-86c6-db9cc09dbcea",
   "metadata": {},
   "source": [
    "### This segment strips off the col names of numbers and produces \"df_m_ib77_nn\" and demonstrates slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "206a3e44-8616-4091-bfd1-050c707a94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify slicing df_ib77_nn[['ID','Test Date / Time','ECW/TBW']]  #,\"SMM (Skeletal Muscle Mass)\" , \"Weight\" , \"BMR (Basal Metabolic Rate)\" , \"ECW/TBW\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f195eff-5777-47fd-a97b-6cf913663a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib77_nn = strip_numbers_from_columns(df_ib77_raw)\n",
    "#verify print(list(df_ib77_nn.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b7bac-39f9-41bd-8001-dc928aeaa1cf",
   "metadata": {},
   "source": [
    "### This segment eliminates duplicates in **df_ib77_nn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3695f30b-1f0a-4025-97e7-de208f996c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed duplicate columns: ['Systolic', 'Diastolic', 'Pulse', 'Mean Artery Pressure', 'Pulse Pressure', 'Rate Pressure Product']\n"
     ]
    }
   ],
   "source": [
    "# Seek out and drop duplicates\n",
    "df_ib77_nn = drop_duplicate_columns(df_ib77_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c80793b-f4aa-43bd-beeb-7be157dfdcbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ib77_nn , No numbers, no duplicates OK\n"
     ]
    }
   ],
   "source": [
    "# Testing duplicates in the column titles\n",
    "df_ib77_nn.columns[df_ib77_nn.columns.duplicated()]\n",
    "\n",
    "print (\"df_ib77_nn , No numbers, no duplicates OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af3666-d670-4664-8372-5b89462c01a2",
   "metadata": {},
   "source": [
    "### This segment adds **media_cols** and fills them from data in the results **\"df_m_ib77_nn\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91e7d62a-dd49-48e0-9f58-80e287745925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_ib77_nn = prepend_empty_columns(df_ib77_nn, media_lst)\n",
    "# verify df_m_ib77_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1366e32a-468f-42ab-864b-35bec2d0e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_m_ib_tst_nn[media_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffe2c9ea-44f5-4c1b-aec9-fedfd32de66d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot assemble with duplicate keys",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# fill_ib_media_cols(df_m_ib_tst_nn)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mfill_ib_media_cols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_m_ib77_nn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# verify \u001b[39;00m\n\u001b[32m      4\u001b[39m df_m_ib77_nn  \u001b[38;5;66;03m#[media_lst]\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mfill_ib_media_cols\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     13\u001b[39m df = df.copy()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# --- 1. timestamp (correct parsing) ------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTest Date / Time\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m%\u001b[39;49m\u001b[33;43mH\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mM\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoerce\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# --- 2. dtv: days since 1900‑01‑01 -------------------------\u001b[39;00m\n\u001b[32m     23\u001b[39m origin = pd.Timestamp(\u001b[33m\"\u001b[39m\u001b[33m1900-01-01\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:1075\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m     result = \u001b[43m_assemble_from_unit_mappings\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[32m   1077\u001b[39m     cache_array = _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/pandas/core/tools/datetimes.py:1170\u001b[39m, in \u001b[36m_assemble_from_unit_mappings\u001b[39m\u001b[34m(arg, errors, utc)\u001b[39m\n\u001b[32m   1168\u001b[39m arg = DataFrame(arg)\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arg.columns.is_unique:\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot assemble with duplicate keys\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1172\u001b[39m \u001b[38;5;66;03m# replace passed unit with _unit_map\u001b[39;00m\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(value):\n",
      "\u001b[31mValueError\u001b[39m: cannot assemble with duplicate keys"
     ]
    }
   ],
   "source": [
    "# fill_ib_media_cols(df_m_ib_tst_nn)\n",
    "fill_ib_media_cols(df_m_ib77_nn)\n",
    "# verify \n",
    "df_m_ib77_nn  #[media_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe3891-d5b6-4863-b596-4a9e04904324",
   "metadata": {},
   "source": [
    "### This segment eliminates duplicates based on **\"test_time\" in **\"df_m_ib77_nn\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea0b3eaa-8c81-4824-97c2-24c7e5d4b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_ib77_nn = drop_duplicates_by_test_time(df_m_ib77_nn, keep='first', log=True)\n",
    "#df_m_ib77_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a53c3-4fec-4fb7-9f49-a9e763110181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_m_ib_tst_nn[media_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad3678-a1c8-4cc5-94a9-ac00faa8623e",
   "metadata": {},
   "source": [
    "# WORKING cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a01b35-cc8c-4b2d-b70f-f0de0ddf0b35",
   "metadata": {},
   "source": [
    "#### Calculate excess columns in the main data frame compared the columns in the IB77 data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cd8ae-911b-45f9-a091-65ddd273288c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verify that we have the main data frame\n",
    "df_m_ib_tst.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24613d6-59d6-4d9c-92c2-d713ff0011ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Verify that we have data from data frame to be added to the main data frame \n",
    "# If it's not there read it from pickle\n",
    "# verify df_ib77_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5223165-4ddc-496d-88de-61e6e133fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ the IB77 Columns without numbers FROM pickle \n",
    "with open(\"df_ib77_raw_nms.pkl\", \"rb\") as f:\n",
    "    df_ib77_raw_nms = pickle.load(f)\n",
    "# Verify df_ib77_raw_nms\n",
    "print (\"from pkl df_ib77_raw_nms.pkl OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b4861-816a-4dee-a29d-61ae21594be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IB77 Columns without numbers to pickle \n",
    "with open(\"df_ib77_raw_nms.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_ib77_raw_nms, f)\n",
    "print (\"df_ib77_raw_nms.pkl OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856735be-98d6-41ec-9704-c45fe5a0666f",
   "metadata": {},
   "source": [
    "## Read the latest data from ib77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e54767-e829-4745-a71a-198faf25c3a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ADD MEDA , CLEAN AND SORT  >>>>   **df_m_ib_tst_nn**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f1eb8-a2b1-4408-9f5e-f47f3c44ac08",
   "metadata": {},
   "source": [
    "## Fill in the meta columns by reading the data in the rest of the columns >>> **df_m_ib_tst_nn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864749ba-a381-4281-b07f-03e01d5e716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_m_ib_tst_nn[media_lst].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1dfe70-a1fa-4cd6-8899-c9f62d3831df",
   "metadata": {},
   "source": [
    "## Sort the data frame on the basis of timestamp you >> **df_m_ib_tst_s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73dfbf3-72fe-4c89-81f6-dfb7ebfd831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_ib_tst_nn_s = sort_by_timestamp(df_m_ib_tst_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaba1ce-c4ed-4ed3-a6b7-c6f559bcf993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verify \n",
    "df_m_ib_tst_nn_s[media_lst].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5c51b-cfaa-4608-aefe-444ca503c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify \n",
    "df_m_ib_tst_nn_s[[\"dtv\", \"ib_id\" , \"SMM (Skeletal Muscle Mass)\" , \"Weight\" , \"BMR (Basal Metabolic Rate)\" , \"ECW/TBW\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21aca8-16e0-40ae-b595-cc22c725e94d",
   "metadata": {},
   "source": [
    "## Remove duplicates [...xd]  Retaining the first of a duplicate pair  >>> **df_m_ib_tst_s_xd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebed55-9ee2-4679-9a8a-7aec560b634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_ib_tst_nn_s_xd  =  remove_ib_duplicates(df_m_ib_tst_s, subset_cols=None)\n",
    "# verify df_m_ib_tst_nn_s_xd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ce5d87-f105-4cdc-8059-e5e3681990e5",
   "metadata": {},
   "source": [
    "## Slicing the fully processed data frame [df_m_ib_tst_nn_s_xd] to display columns of interest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9256f2-1375-4170-89d6-5b0d10fa395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify \n",
    "df_m_ib_tst_nn_s_xd[[\"dtv\",\"timestamp\",\"SMM (Skeletal Muscle Mass)\" , \"Weight\" , \"BMR (Basal Metabolic Rate)\" , \"ECW/TBW\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570cbf6-f508-4731-8949-702f8fbea907",
   "metadata": {},
   "source": [
    "# The stored data is loaded checked and verified, and ready to receive new data\n",
    "1. **\"df_m_ib_tst\"**\n",
    "2. **\"df_m_ib_tst_nms\"**\n",
    "3. **\"df_ib97_tst\"**\n",
    "4. **\"df_ib97_tst_nms\"**\n",
    "5. **\"df_ib77_tst\"**\n",
    "6. **\"df_ib77_tst_nms\"**\n",
    "7. **\"_______________\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36254c64-2298-4459-b044-ed7a6a178fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_ib_tst_nms = list(df_m_ib_tst.columns)\n",
    "#df_ib77_raw_nms with numbers \n",
    "#verify  df_m_ib_tst_nms\n",
    "print(\"df_m_ib_tst_nms w/o numbers OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7239a8-92f5-4e4b-9c7a-ffee073bfe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing duplicates in the column titles\n",
    "df_m_ib_tst.columns[df_m_ib_tst.columns.duplicated()]\n",
    "print(\"df_m_ib_tst_nms w/o numbers no duplicate OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e2c756-a86f-4f72-9e76-48c3425c18d3",
   "metadata": {},
   "source": [
    "# This will load the ib77 into the accumulated data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "711b942b-e473-482e-a79b-72b9ea88a0cf",
   "metadata": {},
   "source": [
    "# verify df_m_ib_tst_nms\n",
    "#print(\" The main df_m_ib_tst_nms is in place with no numbers:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca544f-255a-463f-8e5a-5ec2f2c3cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_m_ib_tst\n",
    "print(\" The main df_m_ib_tst is in place with col numbers:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7d30c-4302-43d8-986b-137856e1d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify df_m_ib_tst_nn\n",
    "df_m_ib_tst_nn = strip_numbers_from_columns(df_m_ib_tst)\n",
    "df_m_ib_tst_nn\n",
    "print(\" The main df_m_ib_tst_nn is in place w/o col numbers:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48910d5c-1ee5-462d-9e0f-567b09a593d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the IB77 columns that still have the numbers attached\n",
    "ib77_raw_missing_cols_n = [col for col in ib77_raw.columns \n",
    "                           if col not in df_m_ib_tst_nn.columns]\n",
    "\n",
    "# verify ib77_raw_missing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad59e23-2ad3-40ee-86e5-0ea1be27faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ib77_raw_missing_cols:\n",
    "    ib77_raw[col] = np.nan\n",
    "ib77_raw              # [\"ECW/TBW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c06d4-5add-46c7-b4f5-fa18cc1bcf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose missing_cols is a list of column names you want to add\n",
    "new_cols = pd.DataFrame({col: [None] * len(ib77_raw) for col in missing_cols})\n",
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db289fd-9e57-4d2d-9ac9-504356e11186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add them in one operation\n",
    "ib77_raw = pd.concat([ib77_raw, new_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820e233-e7b7-43c8-8e47-b652356b302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any missing columns to IB77_raw\n",
    "for col in df_m_ib_tst.columns:\n",
    "    if col not in ib77_raw.columns:\n",
    "        ib77_raw[col] = None\n",
    "# verify \n",
    "ib77_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85c7ed-b418-4dde-b8ab-7d3460c91bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib77_raw[[\"BMR (Basal Metabolic Rate)\" , \"ECW/TBW\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061d280-dca5-4954-b30a-c2c72d8bb424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The main data frame is larger than the add data frame so we need To determine the Missing columns.\n",
    "missing_cols = [c for c in df_m_ib_tst.columns if c not in df_ib77_raw.columns]\n",
    "#verify missing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724ad99-24e3-4b91-88a8-d36125b58994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the missing_cols dataframe in order add columns with NAn values to the ib77 values so it can be appended to with the main data frame \"df_m_ib_tst\n",
    "df_ib77_cncnt = df_ib77_raw.copy()    # start building the df\n",
    "#verify df_ib77_cncnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526aee4-a675-437c-bf71-e7d0134d770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Add missing columns\n",
    "for col in missing_cols:\n",
    "    df_ib77_cncnt[col] = np.nan\n",
    "#verify df_ib77_cncnt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d2513c4-62d3-4f49-985e-68696d4c22ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# RAW didn't use 2. Drop extra columns\n",
    "extra_cols = [c for c in df_ib77_cncnt.columns if c not in df_m_ib_tst_nms.columns]\n",
    "df_ib77_cncnt = df_ib77_cncnt.drop(columns=extra_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3644e-75f6-443b-9725-3833499295bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Reorder to match master schema\n",
    "df_ib77_cncnt = df_ib77_cncnt[df_m_ib_tst.columns]\n",
    "#verify df_ib77_cncnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744902-6c48-4dc9-9265-4f0921ec98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Append\n",
    "df_m_ib_tst = pd.concat([df_m_ib_tst, df_ib77_cncnt], ignore_index=True)\n",
    "#verify df_m_ib_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd161a33-9034-47a6-b854-1a01d03f9c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e5701-8196-46ef-bd0e-d8e226742a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698686d-534d-4289-8c95-58a35477cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622db29f-1cb2-421e-bc12-fba131f7fe98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79fb6e6-6311-43a4-a843-34f099835cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5df0d-beab-493e-96f0-61f806c90f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing columns when df_ib77 raw data is appended to IB_tst Data frame\n",
    "df_ib77_raw_missing_cols_n = [col for col in df_ib77_raw.columns if col not in df_m_ib_tst.columns]\n",
    "# verify \n",
    "df_ib77_raw_missing_cols_n\n",
    "print (\"df_ib77_raw_missing_cols_n with numbers  OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd390739-e44f-4ee2-ae34-0009d1c98198",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# strip numbers off So that the identical names in ib77 are the same as 97\n",
    "df_ib77_raw_missing_cols_nms = strip_col_numbers(df_ib77_raw_missing_cols_n)\n",
    "# Verify \n",
    "df_ib77_raw_missing_cols_nms\n",
    "print (\"df_ib77_raw_missing_cols_nms w/o numbers  OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e915e3-74d6-4f21-9981-f555dc6d4cdb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the df_ib77_raw_missing_cols_nms to pickle \n",
    "with open(\"df_ib77_raw_missing_cols_nms.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_ib77_raw_missing_cols_nms, f)\n",
    "print (\"df_ib77_raw_missing_cols_nms.pkl OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4512076-b999-4907-b42c-62e23822d64d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# READ thedf_ib77_raw_missing_cols_nms FROM pickle \n",
    "with open(\"df_ib77_raw_missing_cols_nms.pkl\", \"rb\") as f:\n",
    "    df_ib77_raw_missing_cols_nms = pickle.load(f)\n",
    "# Verify df_ib77_raw_missing_cols_nms\n",
    "print (\"from pkl df_ib77_raw_missing_cols_nms.pkl OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9eae66-620f-43e4-a1ce-3f025582f18f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate missing columns when df_ib77 raw data is appended to ib_tst DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129a8e1-1f9b-43c7-a612-be8dde301649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4070b200-9825-468c-bb85-23c68d0f3883",
   "metadata": {},
   "source": [
    "## Calculate the **ib_tst** columns that are not used when **ib77** is concatenated =  **xcss77**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e372e40e-f686-4ee0-9385-ba6cacabf0dd",
   "metadata": {},
   "source": [
    "### ib97:  This segment Reads the data from the excel file_ib97 and computes names of the column head, strips them of numbers and Puts them in a list and records them in a pickle. *ib97_raw_nms*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ee192-fffe-4024-b652-9f2e6f1f6ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loads the new from the 970\n",
    "ib97_raw = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib97\", \n",
    "    pattern=\"*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12cf91-e5a7-4cda-a9df-46a6a894e61e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ib97_raw_nms = list(ib97_raw.columns)\n",
    "# Verify \n",
    "ib97_raw_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756265d-9680-4f06-8855-a5696040b23b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# strip numbers off So that the identical names in ib97 are the same as ib97\n",
    "ib97_raw_nms = strip_col_numbers(ib97_raw)\n",
    "# Verify\n",
    "ib97_raw_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce882e-7c4e-432f-aa0f-76e54b782da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097220ea-88b4-4bf1-8a26-5924e958d083",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the IB97 Columns without numbers to pickle \n",
    "with open(\"ib97_raw_nms.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ib97_raw_nms, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74340ccb-0d5f-4dd1-934d-756550b5e693",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# READ the IB97 Columns without numbers to pickle \n",
    "with open(\"ib97_raw_nms.pkl\", \"rb\") as f:\n",
    "    ib97_raw_nms = pickle.load(f)\n",
    "# Verify ib97_raw_nms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f196f-0df6-4bec-b5dc-d1fb3dd84ce4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### The following data are loaded and ready to be consolidated into an updated Total data data frame \"m_bi_tst\" from :XL >>> \"df_m_bi_tst\" and new\"df_ib97_raw\",new \"df_ib77_raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8c021-72c0-4953-8afd-049cd5738175",
   "metadata": {},
   "source": [
    "### This will load the ib97 into the accumulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d52420-10b7-4881-bcdf-e0a78c38d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any missing columns to IB97_raw\n",
    "for col in m_ib_tst.columns:\n",
    "    if col not in ib97_raw.columns:\n",
    "        ib97_raw[col] = None\n",
    "# Reorder IB97_raw columns to match m_ib_tst\n",
    "ib97_raw = ib97_raw[m_ib_tst.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b86e80-f9eb-4090-8428-344f9a02eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ib_tst = pd.concat([m_ib_tst, ib97_raw], ignore_index=True)\n",
    "m_ib_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f4544c-735f-4611-9d52-ca4643f66466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c809e5-a8f6-4c50-8dbe-0a61d781359f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4175d-b8f3-4405-9ead-82220b09363d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf670fa-f6d9-4205-a739-fb86ccc7d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder ib77_raw columns to match df_m_ib_tst\n",
    "ib77_raw = ib77_raw[df_m_ib_tst.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21f925-e779-4977-8c4b-3c6ec25c2812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This concatenates 770 new data with the existing data That contains the accumulator data from 770 and 970\n",
    "df_m_ib_tst = pd.concat([df_m_ib_tst, ib77_raw], ignore_index=True)\n",
    "#verify df_m_ib_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6771167-d77a-4a95-8254-9cbb929d853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This checks to see if column names are still all unique after the new data\n",
    "df_m_ib_tst.columns[df_m_ib_tst.columns.duplicated()]\n",
    "print(\" No duplicates found Afternoon data was appended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50c377-960b-4737-b2d6-dd86e27b14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_ib_tst[\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03369ea4-b877-4ae2-9a15-fdeff33345de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib77_raw.columns[ib77_raw.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55492f-8954-4a51-a43a-dada463d72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_ib_tst_s_xd[[\"dtv\",\"SMM (Skeletal Muscle Mass)\" , \"Weight\" , \"BMR (Basal Metabolic Rate)\" , \"ECW/TBW\"]].head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b157d3d3-b341-4c6e-beed-d7946638de6c",
   "metadata": {},
   "source": [
    "ib77_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41200b5-ed0d-498b-9332-bbb3b175152c",
   "metadata": {},
   "source": [
    "# load latest [m_ib_tst] to xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d5df7-4abb-4235-a6fd-362083346d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latest [m_ib_tst] from_xl\n",
    "folder_path = \"/home/bhuns/JL_2/data/ib_tst/m_ib_tst.csv\"\n",
    "m_ib_tst.to_csv(folder_path, index=False)\n",
    "# verify\n",
    "#\n",
    "m_ib_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5002b-a036-4bbb-9516-ccfb3aeb2ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addede9b-2751-44a4-8f41-b46faaf2414c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Everything below this line is residual the days the template was developed and completed. Erase it when everything using the template is completed\n",
    "# ================================================================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac9c77-ea9b-4519-a678-5b00f0dd9e9d",
   "metadata": {},
   "source": [
    "# Startup only Create  **df_ib_fls_tmplt**  ie  *[COL_NMS = meta+ib770dat + ib970dat]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db50dc4-2a25-40a9-b5bd-788531d503e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fca89a-63f7-4be1-92ef-328a48a4d1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a09cda-cde5-49e3-b531-ab00768c86b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d9b2c-b05b-4109-9223-fbb420d57b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002e3f1-ac98-41a6-88a2-8d472fda8f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2314cef7-0753-46cb-9da3-28a3a1968b43",
   "metadata": {},
   "source": [
    "### Both the 77 and the 90 test datasets are convrted to dfs In order to determine *df_ib_tst_nms* Which is a single column data frame that all of the column names of the *df_ib_tst*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb2f2af-640c-418d-b976-f966ed95e981",
   "metadata": {},
   "source": [
    "#### ✅ Concatenate → Preserve Order → Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162178e7-84e1-4591-9be5-c2fb1c903aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  Concatenate → Preserve Order → Drop Duplicates mmmmmmmmmnnnnnnnllllll\n",
    "# Concatenate in the required order\n",
    "df_ib_tst_nms = pd.concat(\n",
    "    [df_ib77_raw_nms, df_ib97_raw_nms],\n",
    "    axis=0,\n",
    "    ignore_index=True\n",
    ")\n",
    "# print(df_ib_tst_nms)\n",
    "# Remove duplicate rows, keeping the first occurrence (from df_ib77_raw_nms)\n",
    "df_ib_tst_nms = df_ib_tst_nms.drop_duplicates(keep=\"first\")\n",
    "# verify \n",
    "# print(df_ib_tst_nms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda01c2-e3f4-43f6-a730-78af5ba12e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifies that the duplicates have been removed and that the list has been compacted and there are not duplicates of 770 and 970 Col\n",
    "df_ib_tst_nms[df_ib_tst_nms.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c4d50e-0a5b-4074-9da9-b3d85ca13fbf",
   "metadata": {},
   "source": [
    "### *df_ib_tst_nms* must be converted to a simple list in order to made equal to the column heads of df_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c74182-c2e5-41ae-937b-54882528df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The large test data frame that will be used to accept values of each from both 770 N 970 will be built on the basis of the df_ib_tst_nms, but this data bugs be in form of a strings.\n",
    "# df['colname'].astype(str).tolist       # sign This is the sample given from copilot that is modified below for my situation \n",
    "\n",
    "ib_tst_lst = df_ib_tst_nms[0].astype(str).tolist()\n",
    "# verify \n",
    "# print(ib_tst_lst)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68b5135d-8592-4d58-9002-cbd154f61251",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#  Raw not needed\n",
    "df_ib_tst.columns = [\n",
    "    \"_\".join([str(c) for c in col]).strip()\n",
    "    if isinstance(col, tuple) else col\n",
    "    for col in df_ib_tst.columns\n",
    "]\n",
    "df_ib_tst[\"ID\"]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5e4eebc-ece3-4137-ab01-97f6005a6654",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# RAW Since the column names are listed in a data frame That makes each one a tuple. It must be a string. Line makes it a string and the column a list of strings.\n",
    "df_ib_tst_nms = [col[0] if isinstance(col, tuple) else col for col in df_ib_tst_nms]\n",
    "df_ib_tst_nms = df_ib_tst.columns \n",
    "df_ib_tst_nms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21ba0884-3bf5-46ed-87bd-d38a3edd4595",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "raw\n",
    "df_ib_tst.columns = [col[0] if isinstance(col, tuple) else col for col in df_ib_tst.columns]\n",
    "df_ib_tst.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6f09a-ac5f-48a9-a379-e732c8c5194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes the template for the ib_tst data For both the 770 and the 970 It is made up of a 770 and a 970 with duplicates eliminated in a list of strings\n",
    "\n",
    "df_ib_tst = pd.DataFrame(\n",
    "    data = [[\"\"] * len(df_ib_tst_lst)] * 2,\n",
    "    columns = ib_tst_lst\n",
    ")\n",
    "#df_ib_tst_nms\n",
    "df_ib_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581a42d-3b59-4274-b436-8b70c3b2dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests \n",
    "df_ib_tst[\"ID\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786015c-3b7b-4611-9130-38413ff07172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib_tst.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7350e-6a9e-44f5-8ec3-2602489ec699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib_tst[\"ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3cf4af-3568-4d4a-b892-9b4406dd0db6",
   "metadata": {},
   "source": [
    "## data frame of the main data storage_“ib_tst\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf894513-6122-4256-9011-3c35d9133682",
   "metadata": {},
   "source": [
    "###  Make the edits to the structure of the main data spreadsheet that represents structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855723c-7ca0-45f8-b26a-d8d49c37997d",
   "metadata": {},
   "source": [
    "### Then the CSV file into the worksheet to display the changes in Jupiter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca560b7-1dad-43b3-b1cd-41c85e021ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_csv(\"/home/bhuns/JL_2/data/ib_tst/ib_tst.csv\")\n",
    "df_loaded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aeba15-4cb8-42b1-aeb7-d7ad491e32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/bhuns/JL_2/data/ib_tst/ib_tst.csv\"\n",
    "df_ib_tst.to_csv(folder_path, index=False)\n",
    "df_ib_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cddd21-4dda-4757-aef6-b823e9b028fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded[\"Age\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0ce26-77c8-442e-ab62-60f150d7c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================================================================================================== Oh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74c0e6-120f-4305-bf1f-88d213250550",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa929e-64d5-42cf-aa16-51d29dc58617",
   "metadata": {},
   "source": [
    "\n",
    "# Align the columns via index suggestions from Copilot to insert new data into the major data frame\n",
    "\n",
    "Put the creation of a data frame into its own worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8af45b-1a8b-4e2e-b03b-ae1230a770fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d1773-8941-461a-8d13-e1f38b0bd09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8e79156-2206-4f99-8518-022d22456a22",
   "metadata": {},
   "source": [
    "# =============================================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f860afb-3eae-4a44-bab8-918884bb0951",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def strip_numbers_from_columns(df):\n",
    "import re\n",
    "def strip_numbers_from_columns(df):\n",
    "    \"\"\"\n",
    "    Removes leading or trailing numbers (and optional separators)\n",
    "    from column names without altering descriptor text.\n",
    "    Examples cleaned:\n",
    "      '1 Weight' → 'Weight'\n",
    "      'Weight 1' → 'Weight'\n",
    "      '2-Height' → 'Height'\n",
    "      '3_TBW' → 'TBW'\n",
    "      '4:LBM' → 'LBM'\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    new_cols = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        # Remove leading numbers + separators\n",
    "        cleaned = re.sub(r'^\\d+[\\s\\-\\_:]*', '', col)\n",
    "        # Remove trailing numbers + separators\n",
    "        cleaned = re.sub(r'[\\s\\-\\_:]*\\d+$', '', cleaned)\n",
    "        new_cols[col] = cleaned\n",
    "\n",
    "    df = df.rename(columns=new_cols)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243af1df-97ba-4ee9-9b88-c49a26337c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_lst = [\n",
    "    \"Test Date / Time\",\n",
    "    \"timestamp\",\n",
    "    \"dtv\",\n",
    "    \"ib_id\",\n",
    "    \"cls\",\n",
    "    \"cmmnts\"\n",
    "]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
