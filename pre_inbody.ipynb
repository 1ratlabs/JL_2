{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52f2da4-ba8f-4ee0-981e-53ad60a73aa7",
   "metadata": {},
   "source": [
    "# Procedure when data added ; Start from \"pre_inbody.\" [HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e174ab8-e3d9-42bd-ba0f-f914aea2938c",
   "metadata": {},
   "source": [
    "## Can use \"[RESET/RESTART]\" because recalculated data is stored in pickle\n",
    "1. Move new data from \"C:\\Users\\bhuns\\OneDrive\\___Health Data\\__DD studies\\InBody CSV\\ib97\" into \"JL_1/data/ib97\"\n",
    "2. GO to \"pre_inbody\"  and Hit >> [RESET/RESTART] to erase old results, reset kernal and run the cell. [Results in pickle]\n",
    "3. GO to \"nrmlz_data_dict\"  and Hit >> [RESET/RESTART] to erase old results, reset kernal and run the cell. [Results in pickle]\n",
    "4. GO to \"plot_sandbox\"  and Hit >> [RESET/RESTART] to erase old results, reset kernal and run the cell. [Results in graphs]\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc44cd5a-40d5-4bff-8dde-de21b6877ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bhuns/miniconda3/bin/python\n",
      "note: THIS IS THE DIRECTORY PYTHON IS WORKING IN.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(\"note: THIS IS THE DIRECTORY PYTHON IS WORKING IN.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb72ef-b02f-48c2-a659-88d6c3fee5e2",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e1c6941-4bbc-421d-bcf4-ee3bb2055a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports required for Loading, sorting .csx files to create specific data sets ie mrn inbody readings. \n",
    "%run ./sys_funcs.py              # loads all the def functions in sys_funcs.py into memory\n",
    "#import sys_funcs                 # gives access to these def function digitalform that are in memory\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import time\n",
    "from sys_funcs import read_csv_to_array\n",
    "from sys_funcs import clean_wsl_path\n",
    "from sys_funcs import array_to_dt_row_dict\n",
    "from sys_funcs import make_blnk_update_row_dict\n",
    "from sys_funcs import transpose_csv_to_col_dict\n",
    "#from sys_funcs import update_values_with_config, get_update_result\n",
    "from sys_funcs import transfer_updates\n",
    "from sys_funcs import get_dtv_range\n",
    "from sys_funcs import universal_import\n",
    "from sys_funcs import parse_inbody_timestamp\n",
    "from sys_funcs import build_lut\n",
    "from sys_funcs import extract_a_column_as_df\n",
    "from sys_funcs import extract_multicolumns_as_df\n",
    "from sys_funcs import validate_and_sort_timestamps\n",
    "from sys_funcs import extract_and_filter_by_time_window\n",
    "from sys_funcs import read_file_dual_path\n",
    "from sys_funcs import write_file_dual_path\n",
    "from sys_funcs import asc_to_csv_cnv\n",
    "#from sys_funcs import "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d6002-aa53-4f83-b96e-abedf1fceb86",
   "metadata": {},
   "source": [
    "# DEF functions for this workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6b9008e8-0977-4a44-9b04-ff8b2aec28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the list in the call and this function will:\n",
    "# ask for a substring and make a list of names that contain it.\n",
    "def filter_column_names_interactive(df_col_nms):\n",
    "    \"\"\"\n",
    "    Prompts for a substring and prints matching column names from df_col_nms.\n",
    "    Assumes df_col_nms is a single-column DataFrame of column names.\n",
    "    \"\"\"\n",
    "    substring = input(\"Enter substring to filter column names: \").strip()\n",
    "    matches = df_col_nms[df_col_nms.iloc[:, 0].str.contains(substring, case=False, na=False)]\n",
    "    \n",
    "    if matches.empty:\n",
    "        print(f\"No column names contain '{substring}'.\")\n",
    "    else:\n",
    "        print(f\"Column names containing '{substring}':\")\n",
    "        for name in matches.iloc[:, 0]:\n",
    "            print(f\"  - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ae6d4248-736b-4b6e-a986-cb47221b9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this def function takes raw imported a data_dict cleans up the '14. Test Date / Time' then` This 13 for the 770\n",
    "# attachs a \"Cleaned_Timestamp\" and a \"dtv\" \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "503c0610-0370-4e2b-a6c0-f01b041997ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_dict(data_dict):\n",
    "    cleaned_dict = data_dict.copy()\n",
    "    base_date = datetime(1900, 1, 1)\n",
    "\n",
    "    def safe_parse(ts):\n",
    "        try:\n",
    "            return (datetime.strptime(ts, \"%Y%m%d%H%M%S\") - base_date).days\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse timestamp {ts}: {e}\")\n",
    "            return np.nan\n",
    "\n",
    "    timestamps = data_dict.get(\"13. Test Date / Time\", [])\n",
    "    cleaned_dict[\"Cleaned_Timestamp\"] = [\n",
    "        str(ts).strip()[:14] if str(ts).strip().lower() != \"nan\" and len(str(ts).strip()) >= 14 else np.nan\n",
    "        for ts in timestamps\n",
    "    ]\n",
    "    cleaned_dict[\"dtv\"] = [\n",
    "        safe_parse(ts) if isinstance(ts, str) and len(ts) == 14 else np.nan\n",
    "        for ts in cleaned_dict[\"Cleaned_Timestamp\"]\n",
    "    ]\n",
    "    return cleaned_dict\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df2a55fe-a4e0-493e-b31e-0806b8838121",
   "metadata": {},
   "source": [
    "Replaced by above\n",
    "def clean_data_dict(data_dict):\n",
    "    \"\"\"\n",
    "    Cleans the input data_dict by:\n",
    "    - Stripping and truncating '14. Test Date / Time' to 14 characters\n",
    "    - Creating a 'Cleaned_Timestamp' column\n",
    "    - Creating a 'dtv' column: days since 1/1/1900\n",
    "    Returns a cleaned copy of the input dictionary.\n",
    "    \"\"\"\n",
    "    cleaned_dict = data_dict.copy()\n",
    "\n",
    "    # Step 1: Clean and truncate timestamp strings\n",
    "    cleaned_dict[\"Cleaned_Timestamp\"] = [\n",
    "        str(ts).strip()[:14] if str(ts).strip().lower() != \"nan\" and len(str(ts).strip()) >= 14 else np.nan\n",
    "        for tststststs in cleaned_dict.get(\"14. Test Date / Time\", [])\n",
    "    ]\n",
    "\n",
    "    # Step 2: Convert to datetime and calculate days since 1/1/1900\n",
    "    base_date = datetime(1900, 1, 1)\n",
    "    def safe_parse(ts):\n",
    "        try:\n",
    "            return (datetime.strptime(ts, \"%Y%m%d%H%M%S\") - base_date).days\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    cleaned_dict[\"dtv\"] = [\n",
    "        safe_parse(ts) if isinstance(ts, str) and len(ts) == 14 else np.nan\n",
    "        for ts in cleaned_dict[\"Cleaned_Timestamp\"]\n",
    "    ]\n",
    "\n",
    "    return cleaned_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e277b49-0cd8-4fa9-95e9-e2e93c74ec70",
   "metadata": {},
   "source": [
    "# Create **ib970** by Loading **970.csv** files"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b75fb136-0159-498d-baae-0a3ce14c358f",
   "metadata": {},
   "source": [
    "# RAW for saftey gets only 1\n",
    "# Loads all the files from ib970 file  >>> folder_path=\"/home/bhuns/JL_1/data/ib97\",\n",
    "# those are copied in from \"C:\\Users\\bhuns\\OneDrive\\___Health Data\\__DD studies\\InBody CSV\\ib97\"\n",
    "# uses \"from sys_funcs import universal_import\"\n",
    "ib970 = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib97\",\n",
    "    pattern=\"091725*\",\n",
    "    #expected_columns=250,\n",
    "    df_name=\"ib970\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "698aa149-cc56-4823-b2f2-1d96a7fcf75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "091725\n",
      "âœ… Loaded 091725_bdailyn_20250922225826.csv with ISO-8859-1\n",
      "âœ… [ib970_a] Final DataFrame: 1 rows from 1 files.\n",
      "ðŸ’¾ Saved to pickle: /home/bhuns/JL_2/ib970_a.pkl\n",
      "091725      1. Name    2. ID   3. Height 4. Date of Birth 5. Gender  6. Age  \\\n",
      "0  <bdailyn>  bdailyn  6ft 06.0in      1939.02.23.         M    86.0   \n",
      "\n",
      "  7. Mobile Number 8. Phone Number 9. Zip Code 10. Address  ...  \\\n",
      "0                -               -           -           -  ...   \n",
      "\n",
      "  244. 50kHz-Whole Body Phase Angle_Z score 245. TBW/WT_T Score  \\\n",
      "0                                      -2.6                -1.4   \n",
      "\n",
      "  246. TBW/WT_Z Score  247. SMI(SMM/Wt)_T score  248. SMI(SMM/Wt)_Z score  \\\n",
      "0                -0.3                      -1.9                      -0.6   \n",
      "\n",
      "   249. ECM/BCM_T Score  250. ECM/BCM Z Score  Unnamed: 250  \\\n",
      "0                   8.0                   4.6           NaN   \n",
      "\n",
      "                         source_file  encoding_used  \n",
      "0  091725_bdailyn_20250922225826.csv     ISO-8859-1  \n",
      "\n",
      "[1 rows x 253 columns]\n",
      "Index(['1. Name', '2. ID', '3. Height', '4. Date of Birth', '5. Gender',\n",
      "       '6. Age', '7. Mobile Number', '8. Phone Number', '9. Zip Code',\n",
      "       '10. Address',\n",
      "       ...\n",
      "       '244. 50kHz-Whole Body Phase Angle_Z score', '245. TBW/WT_T Score',\n",
      "       '246. TBW/WT_Z Score', '247. SMI(SMM/Wt)_T score',\n",
      "       '248. SMI(SMM/Wt)_Z score', '249. ECM/BCM_T Score',\n",
      "       '250. ECM/BCM Z Score', 'Unnamed: 250', 'source_file', 'encoding_used'],\n",
      "      dtype='object', length=253)\n",
      "ðŸš« No valid files loaded.\n",
      "251201 Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"091725\")\n",
    "ib970_a = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib97\",\n",
    "    pattern=\"091725*\",\n",
    "    df_name=\"ib970_a\"\n",
    ")\n",
    "print(\"091725\",ib970_a)\n",
    "print(ib970_a.columns)\n",
    "      \n",
    "ib970_b = universal_import(\n",
    "    folder_path=\"/home/bhuns/JL_2/data/ib97\",\n",
    "    pattern=\"251201*\",\n",
    "    df_name=\"ib970_b\"\n",
    ")\n",
    "print(\"251201\",ib970_b)\n",
    "\n",
    "# Combine them (assuming they return DataFrames)\n",
    "import pandas as pd\n",
    "ib970 = pd.concat([ib970_a, ib970_b], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cef327-631b-405a-8f50-c7d68170f82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca0236db-05bb-4aa5-92e3-90cc61dae733",
   "metadata": {},
   "source": [
    "# Create **ib970cln** *and* **df_ib970cln_col_nms** from **ib970**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9002f77-53ac-436c-b799-d32d5879cc7e",
   "metadata": {},
   "source": [
    "## Cleanup the **'13. Test Date / Time'** so **datetime** will work and add cols ie. keys:\n",
    "1. **Cleaned_Timestamp**\n",
    "2. **dtv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "01ae8d8d-adfe-46ac-9a55-024bcdb49cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe\n",
      "dict-like\n",
      "other\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Mapping\n",
    "import pandas as pd\n",
    "\n",
    "def kind_of(var):\n",
    "    if isinstance(var, pd.DataFrame):\n",
    "        return \"dataframe\"\n",
    "    if isinstance(var, Mapping):   # covers dict, OrderedDict, defaultdict, etc.\n",
    "        return \"dict-like\"\n",
    "    return \"other\"\n",
    "\n",
    "# Usage\n",
    "\n",
    "print(kind_of(pd.DataFrame({\"ib970cln \":[1,2]})))  # dataframe\n",
    "print(kind_of({\"ib970cln \": 1}))                   # dict-like\n",
    "print(kind_of([1,2,3]))                            # other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ad527cda-3bd3-4b13-bba3-0b1a96d29596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataframe'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kind_of(ib970)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6240179f-5527-4808-87fd-664b2686aaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. Name</th>\n",
       "      <th>2. ID</th>\n",
       "      <th>3. Height</th>\n",
       "      <th>4. Date of Birth</th>\n",
       "      <th>5. Gender</th>\n",
       "      <th>6. Age</th>\n",
       "      <th>7. Mobile Number</th>\n",
       "      <th>8. Phone Number</th>\n",
       "      <th>9. Zip Code</th>\n",
       "      <th>10. Address</th>\n",
       "      <th>...</th>\n",
       "      <th>244. 50kHz-Whole Body Phase Angle_Z score</th>\n",
       "      <th>245. TBW/WT_T Score</th>\n",
       "      <th>246. TBW/WT_Z Score</th>\n",
       "      <th>247. SMI(SMM/Wt)_T score</th>\n",
       "      <th>248. SMI(SMM/Wt)_Z score</th>\n",
       "      <th>249. ECM/BCM_T Score</th>\n",
       "      <th>250. ECM/BCM Z Score</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>source_file</th>\n",
       "      <th>encoding_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;bdailyn&gt;</td>\n",
       "      <td>bdailyn</td>\n",
       "      <td>6ft 06.0in</td>\n",
       "      <td>1939.02.23.</td>\n",
       "      <td>M</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>091725_bdailyn_20250922225826.csv</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1. Name    2. ID   3. Height 4. Date of Birth 5. Gender  6. Age  \\\n",
       "0  <bdailyn>  bdailyn  6ft 06.0in      1939.02.23.         M    86.0   \n",
       "\n",
       "  7. Mobile Number 8. Phone Number 9. Zip Code 10. Address  ...  \\\n",
       "0                -               -           -           -  ...   \n",
       "\n",
       "  244. 50kHz-Whole Body Phase Angle_Z score 245. TBW/WT_T Score  \\\n",
       "0                                      -2.6                -1.4   \n",
       "\n",
       "  246. TBW/WT_Z Score  247. SMI(SMM/Wt)_T score  248. SMI(SMM/Wt)_Z score  \\\n",
       "0                -0.3                      -1.9                      -0.6   \n",
       "\n",
       "   249. ECM/BCM_T Score  250. ECM/BCM Z Score  Unnamed: 250  \\\n",
       "0                   8.0                   4.6           NaN   \n",
       "\n",
       "                         source_file  encoding_used  \n",
       "0  091725_bdailyn_20250922225826.csv     ISO-8859-1  \n",
       "\n",
       "[1 rows x 253 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify \n",
    "# \n",
    "ib970    # all rows but not in chronological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b65042-c126-4f1a-8c9c-d91c77b3775f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02c761c8-4f2f-4f58-99c7-e79a4f85ac8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# this calls the def clean_data_dict () to clean bad testdate data and add \"dtv\" & \"Cleaned_Timestamp\" NANs still included\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ib970cln = \u001b[43mclean_data_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mib970\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mib970cln has been created with dtv & Cleaned_Timestamp cols added \u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mclean_data_dict\u001b[39m\u001b[34m(data_dict)\u001b[39m\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m     12\u001b[39m timestamps = data_dict.get(\u001b[33m\"\u001b[39m\u001b[33m13. Test Date / Time\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mcleaned_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCleaned_Timestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = [\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mstr\u001b[39m(ts).strip()[:\u001b[32m14\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ts).strip().lower() != \u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(ts).strip()) >= \u001b[32m14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np.nan\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m timestamps\n\u001b[32m     16\u001b[39m ]\n\u001b[32m     17\u001b[39m cleaned_dict[\u001b[33m\"\u001b[39m\u001b[33mdtv\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m     18\u001b[39m     safe_parse(ts) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ts, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ts) == \u001b[32m14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np.nan\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m cleaned_dict[\u001b[33m\"\u001b[39m\u001b[33mCleaned_Timestamp\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     20\u001b[39m ]\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/JL_2/lib/python3.11/site-packages/pandas/core/frame.py:4322\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4319\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4321\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4322\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/JL_2/lib/python3.11/site-packages/pandas/core/frame.py:4535\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4526\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4527\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4528\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4533\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4534\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4535\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4538\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4539\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4540\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4541\u001b[39m     ):\n\u001b[32m   4542\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4543\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/JL_2/lib/python3.11/site-packages/pandas/core/frame.py:5288\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m   5287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m-> \u001b[39m\u001b[32m5288\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5289\u001b[39m arr = sanitize_array(value, \u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5291\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5292\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5295\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5296\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/JL_2/lib/python3.11/site-packages/pandas/core/common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (0) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "# this calls the def clean_data_dict () to clean bad testdate data and add \"dtv\" & \"Cleaned_Timestamp\" NANs still included\n",
    "ib970cln = clean_data_dict(ib970)\n",
    "print(\"ib970cln has been created with dtv & Cleaned_Timestamp cols added \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295671fd-3b26-461f-a6d3-d27266dd8eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verify still not in temporal order yet\n",
    "#\n",
    "ib970cln       #this has all the rows but not in chronological oreder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0437554-f8b7-4b80-a694-00dc5d7f5d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3cf8038-02ea-4aee-82da-987cdc8d8b68",
   "metadata": {},
   "source": [
    "### Read the **df_ib970cln_col_nms** *from* **ib970cln**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698061b5-91e5-42e4-ba3c-f6310cfe655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ib970cln_col_nms = pd.DataFrame(ib970cln.columns)\n",
    "print(\"df_ib970cln_col_nms has been created \")\n",
    "# df_ib970cln_col_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e73e77-7283-4879-bc80-fe00946491ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verify\n",
    "# \n",
    "df_ib970cln_col_nms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a433a6c-7668-43dc-8ede-5b656853da6e",
   "metadata": {},
   "source": [
    "## Save **ib970cln** and **df_ib970cln_col_nms** to **pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55347a68-1224-4cff-add5-d27a2329acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ib970cln to a file\n",
    "import pickle\n",
    "with open(\"ib970cln.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ib970cln, f)\n",
    "print(\" ib970cln is saved to pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ebb35-88a5-44c9-aeff-096043ac06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify \n",
    "# \n",
    "ib970cln    # all rows but not in chronological order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0f97d-7474-49b2-8a06-213f4fe6b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify \n",
    "# \n",
    "ib970cln_dtstmp = ib970cln[[\"dtv\", \"Cleaned_Timestamp\"]]    # time and datestamp df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4abaa-d892-40aa-b0a1-4873c404b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify \n",
    "# \n",
    "ib970cln_dtstmp    #[\"ib970cln_dtstmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60a4f0-cfe5-4546-b57c-2a6aaa49fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_ib970cln_col_nms to a file\n",
    "import pickle\n",
    "with open(\"df_ib970cln_col_nms.pkl\", \"wb\") as f:\n",
    "    pickle.dump( df_ib970cln_col_nms, f)\n",
    "print(\"  df_ib970cln_col_nms is saved to pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e2c02-a7a0-4d8f-b3b4-0772318b7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ib970cln_dtstmp to a file\n",
    "import pickle\n",
    "with open(\"ib970cln_dtstmp.pkl\", \"wb\") as f:\n",
    "    pickle.dump( ib970cln_dtstmp, f)\n",
    "print(\"  ib970cln_dtstmp is saved to pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55c389-deeb-4842-b6f6-cd3752e8b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "# ib970mrn_grp1_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7ceee-3a6e-4cd8-98b9-bae4236600bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "# \n",
    "ib970cln_dtstmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ab96a-1113-4eaa-a5be-aab466bacde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(ib970cln_dtstmp['Cleaned_Timestamp'].sort_values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92646e-9fe0-4e16-bf3b-2b1c55f1b0ad",
   "metadata": {},
   "source": [
    "# Creating  **ib970mrn_grp_dict** from **df_ib970cln_col_nms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0879de-1ac3-40f8-b604-3b8ed484af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(ib970cln['Cleaned_Timestamp'].sort_values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51dcfc1-17cf-4630-965f-1ee3957e4e63",
   "metadata": {},
   "source": [
    "##  **ib970mrn_grp1** from **ib970cln**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d950f559-21db-41f4-a103-bd866d7bbe1a",
   "metadata": {},
   "source": [
    "### Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ddd6a-1484-49e9-9c6b-af00e6c8140e",
   "metadata": {},
   "source": [
    "#### \n",
    "1. used to specify the keys[data_cols] needed in **grp1**\n",
    "2. The are selected from **df_ib970cln_col_nms**\n",
    "3. They are chosen manually by copying the names from **df_ib970cln_col_nms list** and pasting them into **ib970mrn_grp1** specification\n",
    "4. To aid the a subscript from the input reduces the number of cos in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182bcaa-073d-45d6-a7de-5dc0649293bb",
   "metadata": {},
   "source": [
    "#### 1. ib970mrn_grp all have keys= \"dtv\" and \"Cleaned_Timestamp\" + a different set of key combinations. [a key is the name of data col]\n",
    "2. The ib970mrn_grp#_dict {key: grp# .........}\n",
    "3. Each grp# starts with the \"dtv\" & \"Cleaned_Timestamp\" cols ready to have more cols added to the list.\n",
    "4. A filter that shows all the \"df_ib970cln_col_nms\" that contain str supplied by input functions.\n",
    "5. Chosen \"col names\" are copied into the list for that grp#\n",
    "6. The grp# is stored via pickel and is read from pick either to use or to edit.\n",
    "7. When editing, if a grp# does not exist the templet with the 2 cols is profide to star a new group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee4d4e-6fd1-4d12-b99f-c174e9dc8571",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00ef10bc-26e5-4477-b197-db86765dbefb",
   "metadata": {},
   "source": [
    "#### The following readings are not working\n",
    "184. Subcutaneous Fat\n",
    "188. Visceral Fat\n",
    "195. Abdominal Fat\n",
    "196. V/S Ratio(Visceral Fat Area/Subcutaneous Fat Area ratio)\n",
    "197. SFA(Subcutaneous Fat Area)\n",
    "208. 50khz-Ab Impedance\n",
    "209. 250khz-Ab Impedance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ff29404-adb3-465c-92b8-eb80903d0565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Date of Birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Unnamed: 149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>source_file</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>encoding_used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Cleaned_Timestamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>dtv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0              1. Name\n",
       "1                2. ID\n",
       "2            3. Height\n",
       "3     4. Date of Birth\n",
       "4               5. Age\n",
       "..                 ...\n",
       "149       Unnamed: 149\n",
       "150        source_file\n",
       "151      encoding_used\n",
       "152  Cleaned_Timestamp\n",
       "153                dtv\n",
       "\n",
       "[154 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make list of data_col names that have subsript ie THIS IS AN AID TO FIND THE RIGHT DA_COLS\n",
    "df_col_nms = df_ib970cln_col_nms\n",
    "df_col_nms\n",
    "#filter_column_names_interactive(df_col_nms)\n",
    "# filter_column_names_interactive(df_col_nms)\n",
    "# link for ECM&BCM   https://copilot.microsoft.com/shares/J9Fbyou7dZXqDwmDD78S7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab9fa4-2dbe-419a-a874-73f236d4518d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for verification\n",
    "# \n",
    "ib970mrn_grp1_nms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb894b7-cd3c-46f3-bff8-5fb6c71c63b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating  **ib970mrn_grp1** from **ib970cln**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc7ab59-4a8d-48bd-b9a8-c32368be7e47",
   "metadata": {},
   "source": [
    "###  Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a68b7d-6237-4cd8-9201-3e4ba27a6085",
   "metadata": {},
   "source": [
    "#### Extracts selected columns from a dict, validates timestamps, sorts chronologically,\n",
    "    and filters by time-of-day window.\n",
    "\n",
    "    Parameters:\n",
    "    - source_dict: dict â€” your working dict (e.g. ib970cln)\n",
    "    - column_group: list â€” list of column names to extract\n",
    "    - timestamp_col: str â€” name of the timestamp column\n",
    "    - start_time: datetime.time â€” lower bound for time-of-day filter\n",
    "    - end_time: datetime.time â€” upper bound for time-of-day filter\n",
    "\n",
    "    Returns:\n",
    "    - df_filtered: pd.DataFrame â€” cleaned, sorted, and time-window-filtered DataFrame\n",
    "    - df_errors: pd.DataFrame â€” rows with invalid timestamps\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32bd81b-0c3b-4fd6-80da-76355b978da3",
   "metadata": {},
   "source": [
    "###  Steps going from ib970cln to ib970cl_mrn_grp1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc75aff-4ed6-4cae-b38f-c319956ef0ac",
   "metadata": {},
   "source": [
    "#### \n",
    "    # Step 1: Extract selected columns\n",
    "    df = pd.DataFrame({col: source_dict[col] for col in column_group if col in source_dict})\n",
    "\n",
    "    # Step 2: Validate timestamp column\n",
    "    if timestamp_col not in df.columns:\n",
    "        raise ValueError(f\"Timestamp column '{timestamp_col}' not found in selected group.\")\n",
    "\n",
    "    df[timestamp_col] = pd.to_datetime(df[timestamp_col], errors=\"coerce\")\n",
    "\n",
    "    # Step 3: Split valid and invalid timestamps\n",
    "    df_valid = df[df[timestamp_col].notna()].copy()\n",
    "    df_errors = df[df[timestamp_col].isna()].copy()\n",
    "\n",
    "    # Step 4: Sort chronologically\n",
    "    df_valid = df_valid.sort_values(timestamp_col).reset_index(drop=True)\n",
    "\n",
    "    # Step 5: Extract time component\n",
    "    df_valid[\"time_only\"] = df_valid[timestamp_col].dt.time\n",
    "\n",
    "    # Step 6: Filter by time-of-day window\n",
    "    df_filtered = df_valid[\n",
    "        (df_valid[\"time_only\"] >= start_time) &\n",
    "        (df_valid[\"time_only\"] <= end_time)\n",
    "    ].copy()\n",
    "\n",
    "    # Step 7: Drop helper column\n",
    "    df_filtered.drop(columns=[\"time_only\"], inplace=True)\n",
    "\n",
    "    return df_filtered, df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18ba20-6f3b-4ce8-a741-b483a62cd9e9",
   "metadata": {},
   "source": [
    "### Calling functions to implement the evolution from **ib970cln** to  **ib970cl_mrn_grp1** using the **ib970mrn_grp1_nms**\n",
    "1. def extract_and_filter_by_time_window(**ib970cln**, **ib970mrn_grp1_nms**)\n",
    "2. from **sys_funcs.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5764ce-1332-42c2-86c3-1afe9a12d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify \n",
    "# ib970cln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ed734-fb98-4048-a1bc-ca44d94211b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify \n",
    "# \n",
    "ib970mrn_grp1_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2d35a-0367-43c7-a08a-3c8f8030efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uses THIS FUNCTION stored in \"sys_funcS.py to use the the ib970mrn_grp1_nms to collect the right data_cols from ib970cln for ib970mrn_grp1\n",
    "#  IT THEN PERFORMS THE 7 STEPS TO RESULT IN       \"ib970mrn_grp1 \n",
    "column_group = ib970mrn_grp1_nms\n",
    "# no_ no_no_no_no_The following will take morning an eve reading Put # in front below to to do only mnr\n",
    "# no_no_no_no_no_no_bring   to this line to do only mrn reads column_group = df_ib970cln_col_nms\n",
    "#\n",
    "source_dict = ib970cln\n",
    "# select the times to get mrn or all\n",
    "# ib970mrn_grp1,df_errors = extract_and_filter_by_time_window(source_dict, column_group, timestamp_col=\"Cleaned_Timestamp\",start_time=time(4, 0), end_time=time(11, 0))  #mrn\n",
    "ib970mrn_grp1,df_errors = extract_and_filter_by_time_window(source_dict, column_group, timestamp_col=\"Cleaned_Timestamp\",start_time=time(0, 0), end_time=time(23,59))    #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecdaf4-36f9-40dc-9622-63a1ae472448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verify\n",
    "#\n",
    "# ib970mrn_grp1 #[\"dtv\"] #this is the final result \"ib970mrn_grp1\"`\n",
    "# ib970cln #[\"160. 50kHz-Whole Body Phase Angle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245151e-1d55-44bb-8995-f74c084d0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify to see the rejected teststamps\n",
    "# df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c3755-d3b9-45bd-89fd-2fc5cdb5008c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### ib970mrn_grp1[\"14. Weight\"]    \n",
    "pd.set_option('display.max_rows', None)\n",
    "ib970mrn_grp1[['dtv', 'Cleaned_Timestamp','14. Weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab67251-db6b-4a86-90a9-988f3c3a8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind_of(ib970mrn_grp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a6318-8f41-4f1b-943c-5c13028aa48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ib970mrn_grp1 to a file\n",
    "with open(\"ib970mrn_grp1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ib970mrn_grp1, f)\n",
    "print(\" ib970mrn_grp1 is saved to pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc0890-cc2c-45bd-a59c-a216647d2c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbd798-aa7e-4f57-846f-c5ba11fc4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify\n",
    "# ib970mrn_grp1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c6c37-85cf-4f55-a66f-e92bcf585651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ib970mrn_grp1_nms to a file\n",
    "with open(\"ib970mrn_grp1_nms.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ib970mrn_grp1_nms, f)\n",
    "print(\" ib970mrn_grp1_nms is saved to pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156c94f-a673-466f-9b65-a1581f3854a7",
   "metadata": {},
   "source": [
    "# The rest are spares and duplicates >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49711d8b-dd9c-46a0-8668-06fbc130b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all cells run ip970mrn_grp1 in pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefcab6-8f61-45d1-9295-615ac00b8c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c037e-c6ed-49a2-b750-cc1bca6978d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c61b51-fa20-438d-997a-0227c4e36b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0263ab68-2f82-45f1-adbd-32961a2161e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ef1bd-3b80-402c-9d08-5dc75ba688e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
